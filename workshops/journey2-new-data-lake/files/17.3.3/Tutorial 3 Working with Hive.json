{"paragraphs":[{"text":"%md\n# Tutorial 3: Working with Hive\n\nThis tutorial was built for BDCS-CE version 17.3.1-20 as part of the New Data Lake User Journey: <https://github.com/oracle/learning-library/tree/master/workshops/journey2-new-data-lake>.  Questions and feedback about the tutorial: <david.bayard@oracle.com>\n\nBe sure to run the previous Tutorial: \"Citi Bike New York Introduction and Setup\"\n\nThis tutorial will illustrate using the Shell interpreter to run a few hive command lines and using the JDBC interpreter to run a few hive queries.\n\n## Contents\n\n+ About Apache Hive\n+ Create a Hive Table with the shell interpreter \n+ Running simple queries (select, show databases, show tables)\n+ Query a simple Hive table and graph the results\n+ Next Steps\n\n\nAs a reminder, the documentation for BDCS-CE can be found here: <http://docs.oracle.com/cloud/latest/big-data-compute-cloud/index.html>","dateUpdated":"2017-08-11T13:21:56+0000","config":{"tableHide":false,"editorSetting":{"editOnDblClick":"true","language":"markdown"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Tutorial 3: Working with Hive</h1>\n<p>This tutorial was built for BDCS-CE version 17.3.1-20 as part of the New Data Lake User Journey: <a href=\"https://github.com/oracle/learning-library/tree/master/workshops/journey2-new-data-lake\">https://github.com/oracle/learning-library/tree/master/workshops/journey2-new-data-lake</a>. Questions and feedback about the tutorial: <a href=\"mailto:&#100;a&#x76;i&#100;&#46;b&#x61;&#x79;&#x61;&#114;&#100;@&#111;&#114;&#x61;c&#108;&#101;&#46;&#x63;&#111;m\">&#100;a&#x76;i&#100;&#46;b&#x61;&#x79;&#x61;&#114;&#100;@&#111;&#114;&#x61;c&#108;&#101;&#46;&#x63;&#111;m</a></p>\n<p>Be sure to run the previous Tutorial: &ldquo;Citi Bike New York Introduction and Setup&rdquo;</p>\n<p>This tutorial will illustrate using the Shell interpreter to run a few hive command lines and using the JDBC interpreter to run a few hive queries.</p>\n<h2>Contents</h2>\n<ul>\n  <li>About Apache Hive</li>\n  <li>Create a Hive Table with the shell interpreter</li>\n  <li>Running simple queries (select, show databases, show tables)</li>\n  <li>Query a simple Hive table and graph the results</li>\n  <li>Next Steps</li>\n</ul>\n<p>As a reminder, the documentation for BDCS-CE can be found here: <a href=\"http://docs.oracle.com/cloud/latest/big-data-compute-cloud/index.html\">http://docs.oracle.com/cloud/latest/big-data-compute-cloud/index.html</a></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1502453027893_-1138687587","id":"20160524-153718_1397925708","dateCreated":"2017-08-11T12:03:47+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1322","user":"anonymous","dateFinished":"2017-08-11T13:21:56+0000","dateStarted":"2017-08-11T13:21:56+0000"},{"text":"%md\n# About Apache Hive\n\nApache Hive is a component that enables the use of SQL against a variety of data, including data stored locally, in the Hadoop Distributed File System (HDFS), and in the Object Store.\n\nIn this tutorial, we will use Hive to enable SQL queries against our Citi Bike .csv dataset.\n\nLearn more about Hive here: <https://hive.apache.org/>","user":"anonymous","dateUpdated":"2017-08-11T13:24:22+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","editorHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1502457719833_-329068108","id":"20170811-132159_567952665","dateCreated":"2017-08-11T13:21:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1852","dateFinished":"2017-08-11T13:24:18+0000","dateStarted":"2017-08-11T13:24:18+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>About Apache Hive</h1>\n<p>Apache Hive is a component that enables the use of SQL against a variety of data, including data stored locally, in the Hadoop Distributed File System (HDFS), and in the Object Store.</p>\n<p>In this tutorial, we will use Hive to enable SQL queries against our Citi Bike .csv dataset.</p>\n<p>Learn more about Hive here: <a href=\"https://hive.apache.org/\">https://hive.apache.org/</a></p>\n</div>"}]}},{"text":"%md\n# Create a Hive Table\n\nOur first step will be to define a Hive table on top of our CSV file.  We will show 2 variations.  The first example leverages a \"managed\" table where Hive manages the storage details (internally Hive will leverage HDFS storage).  The second example leverages an \"external\" table where Hive will read the data directly from the Object Store.\n\nWe will use the hive command line running in the shell interpreter to create our tables.","user":"anonymous","dateUpdated":"2017-08-11T13:30:51+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","editorHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1502457869386_1605680869","id":"20170811-132429_1558998735","dateCreated":"2017-08-11T13:24:29+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1948","dateFinished":"2017-08-11T13:30:47+0000","dateStarted":"2017-08-11T13:30:47+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Create a Hive Table</h1>\n<p>Our first step will be to define a Hive table on top of our CSV file. We will show 2 variations. The first example leverages a &ldquo;managed&rdquo; table where Hive manages the storage details (internally Hive will leverage HDFS storage). The second example leverages an &ldquo;external&rdquo; table where Hive will read the data directly from the Object Store.</p>\n<p>We will use the hive command line running in the shell interpreter to create our tables.</p>\n</div>"}]}},{"title":"Create a \"managed\" Bike Table from the CSV file","text":"%sh \n\nCONTAINER=journeyC\nDIRECTORY=citibike\nFILENAME=201612-citibike-tripdata\n\necho \"Object Storage Container Name        :\" $CONTAINER\necho \"Data Set name (remove .zip or .csv)  :\" $FILENAME\necho \"-----------------------------------------------------------------\"\n\n# We will make a copy of our datafile before loading it \n\n# first remove a previous copy if present\nhadoop fs -rm -r /tmp/base.csv\n\n# copy the base data file to a temporary location\n# we are using a managed hive table so the file will be moved into hive\nsudo -u hive hadoop fs -cp swift://$CONTAINER.default/$DIRECTORY/modified/$FILENAME.nh.csv /tmp/base.csv\n\n# run hive\nsudo -u hive hive 2>&1 <<EOF\nDROP TABLE bike_trips;\n\nCREATE TABLE bike_trips ( \nTripDuration int,\nStartTime timestamp,\nStopTime timestamp,\nStartStationID string,\nStartStationName string,\nStartStationLatitude string,\nStartStationLongitude string,\nEndStationID string,\nEndStationName string,\nEndStationLatitude string,\nEndStationLongitude string,\nBikeID int,\nUserType string,\nBirthYear int, \nGender int\n) \nROW FORMAT delimited \nFIELDS TERMINATED BY ',' ;\n\nLOAD DATA INPATH '/tmp/base.csv' into table bike_trips;\n\nSELECT count(*) FROM bike_trips;\n\nexit;\n\nEOF\n","dateUpdated":"2017-08-11T13:31:52+0000","config":{"tableHide":false,"editorSetting":{"editOnDblClick":"false","language":"sh"},"colWidth":12,"editorMode":"ace/mode/sh","editorHide":false,"title":true,"results":{},"graph":{"mode":"table","height":431,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{"DataFile":"base_bike_nh_long.csv","localFS":"/tmp/hive-demo","data":"base_bike_nh.csv","prefix":"/tmp/hive-demo","CONTAINER":"citibike","hadoopFS":"/user/zeppelin/hive-demo","FILENAME":"201612-citibike-tripdata"},"forms":{}},"apps":[],"jobName":"paragraph_1502453027894_-1137533340","id":"20170413-132012_1207762175","dateCreated":"2017-08-11T12:03:47+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1323","user":"anonymous","dateFinished":"2017-08-11T13:30:32+0000","dateStarted":"2017-08-11T13:29:53+0000"},{"text":"%md\n## If the above paragraph seems to hang...\n\nIf you are following these instructions, you have created a very small BDCS-CE cluster with just a single node using 2 OCPUs.  In this environment, you can run out of available threads to run submitted jobs.  If the hive job above seems to hang, this is likely the cause.  The solution is this:\n\n+ Go to the Jobs tab\n+ Look for the Zeppelin job.  This is actually the Spark Session launched for the Zeppelin spark interpreter.  You can abort this job (using the pop-up menu at the right).  When you abort this \"Zeppelin\" job (which is the Spark Session for the spark interpreter), the Hive job should be able to continue.\n+ Then navigate back to this notebook\n","user":"anonymous","dateUpdated":"2017-08-11T13:38:05+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":"true"},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1502458621813_-918211740","id":"20170811-133701_1067316681","dateCreated":"2017-08-11T13:37:01+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2387","dateFinished":"2017-08-11T13:38:05+0000","dateStarted":"2017-08-11T13:38:05+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>If the above paragraph seems to hang&hellip;</h2>\n<p>If you are following these instructions, you have created a very small BDCS-CE cluster with just a single node using 2 OCPUs. In this environment, you can run out of available threads to run submitted jobs. If the hive job above seems to hang, this is likely the cause. The solution is this:</p>\n<ul>\n  <li>Go to the Jobs tab</li>\n  <li>Look for the Zeppelin job. This is actually the Spark Session launched for the Zeppelin spark interpreter. You can abort this job (using the pop-up menu at the right). When you abort this &ldquo;Zeppelin&rdquo; job (which is the Spark Session for the spark interpreter), the Hive job should be able to continue.</li>\n  <li>Then navigate back to this notebook</li>\n</ul>\n</div>"}]}},{"text":"%sh\nCONTAINER=journeyC\nDIRECTORY=citibike\nFILENAME=201612-citibike-tripdata\n\necho \"Object Storage Container Name        :\" $CONTAINER\necho \"Data Set name (remove .zip or .csv)  :\" $FILENAME\necho \"-----------------------------------------------------------------\"\n\n\n# run hive\nsudo -u hive hive 2>&1 <<EOF\nDROP TABLE bike_trips_objectstore;\n\nCREATE external TABLE bike_trips_objectstore ( \nTripDuration int,\nStartTime timestamp,\nStopTime timestamp,\nStartStationID string,\nStartStationName string,\nStartStationLatitude string,\nStartStationLongitude string,\nEndStationID string,\nEndStationName string,\nEndStationLatitude string,\nEndStationLongitude string,\nBikeID int,\nUserType string,\nBirthYear int, \nGender int\n) \nROW FORMAT delimited \nFIELDS TERMINATED BY ',' \nlocation 'swift://$CONTAINER.default/citibike/modified/';\n\n\nSELECT count(*) FROM bike_trips_objectstore;\n\nexit;\n\nEOF\n","user":"anonymous","dateUpdated":"2017-08-11T13:35:49+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1502458306363_-416947388","id":"20170811-133146_1280326847","dateCreated":"2017-08-11T13:31:46+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2201","dateFinished":"2017-08-11T13:35:21+0000","dateStarted":"2017-08-11T13:34:50+0000","errorMessage":"","title":"Create an \"external\" table against the Object Store"},{"title":"Show the Hive tables defined","text":"%sh\n\nsudo -u hive hive 2>&1 <<EOF\nshow tables;\nEOF\n","dateUpdated":"2017-08-11T13:51:20+0000","config":{"tableHide":false,"editorSetting":{"editOnDblClick":"false","language":"sh"},"colWidth":12,"editorMode":"ace/mode/sh","editorHide":false,"title":true,"results":{},"graph":{"mode":"table","height":300,"optionOpen":true,"keys":[{"name":"gender","index":0,"aggr":"sum"}],"values":[{"name":"a.trip_count","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"gender","index":0,"aggr":"sum"},"yAxis":{"name":"a.trip_count","index":1,"aggr":"sum"}}},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1502453027894_-1137533340","id":"20170511-135148_457890564","dateCreated":"2017-08-11T12:03:47+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1324","user":"anonymous","dateFinished":"2017-08-11T13:36:19+0000","dateStarted":"2017-08-11T13:36:03+0000"},{"title":"Sample query via Hive Command Line","text":"%sh\n\nsudo -u hive hive 2>&1 <<EOF\nselect \n case when a.gender=1 then 'Male' when a.gender=2 then 'Female' else 'unknown' end gender ,\n        a.trip_count \nfrom (select gender, count(*) trip_count from bike_trips\ngroup by gender) a;\nEOF","dateUpdated":"2017-08-11T13:51:29+0000","config":{"tableHide":false,"editorSetting":{"editOnDblClick":"false","language":"sh"},"colWidth":12,"editorMode":"ace/mode/sh","editorHide":false,"title":true,"results":{},"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1502453027895_-1137918089","id":"20170425-120754_372055516","dateCreated":"2017-08-11T12:03:47+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1325","user":"anonymous","dateFinished":"2017-08-11T13:36:50+0000","dateStarted":"2017-08-11T13:36:29+0000"},{"text":"%md\n## Working with the JDBC(Hive) interpreter\n\nZeppelin includes a JDBC interpreter that allows you run a query as a paragraph and do some nice formating of the results.  In BDCS-CE, the JDBC interpreter has been pre-configured to connect to Hive.\n\n\nYou can work with the JDBC interpreter and connect to Hive like this:\n\n    %jdbc(hive)\n    select * from my_table;\n","user":"anonymous","dateUpdated":"2017-08-11T13:40:51+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":"true"},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1502458717231_-1724740669","id":"20170811-133837_19001353","dateCreated":"2017-08-11T13:38:37+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2476","dateFinished":"2017-08-11T13:40:51+0000","dateStarted":"2017-08-11T13:40:51+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Working with the JDBC(Hive) interpreter</h2>\n<p>Zeppelin includes a JDBC interpreter that allows you run a query as a paragraph and do some nice formating of the results. In BDCS-CE, the JDBC interpreter has been pre-configured to connect to Hive.</p>\n<p>You can work with the JDBC interpreter and connect to Hive like this:</p>\n<pre><code>%jdbc(hive)\nselect * from my_table;\n</code></pre>\n</div>"}]}},{"user":"anonymous","config":{"colWidth":6,"enabled":true,"results":{},"editorSetting":{"language":"text","editOnDblClick":false},"editorMode":"ace/mode/text"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1502458897170_-1061724725","id":"20170811-134137_1638313959","dateCreated":"2017-08-11T13:41:37+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2703","text":"%jdbc(hive)\nshow tables","dateUpdated":"2017-08-11T13:41:52+0000","dateFinished":"2017-08-11T13:41:46+0000","dateStarted":"2017-08-11T13:41:46+0000","errorMessage":""},{"user":"anonymous","config":{"colWidth":6,"enabled":true,"results":{},"editorSetting":{"language":"text","editOnDblClick":false},"editorMode":"ace/mode/text"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1502458925988_-322976188","id":"20170811-134205_551795930","dateCreated":"2017-08-11T13:42:05+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2841","text":"%jdbc(hive)\ndescribe bike_trips","dateUpdated":"2017-08-11T13:43:21+0000","dateFinished":"2017-08-11T13:43:16+0000","dateStarted":"2017-08-11T13:43:16+0000","errorMessage":""},{"user":"anonymous","config":{"colWidth":6,"enabled":true,"results":{},"editorSetting":{"language":"text","editOnDblClick":false},"editorMode":"ace/mode/text"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1502458940484_-147348444","id":"20170811-134220_795710812","dateCreated":"2017-08-11T13:42:20+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2897","text":"%jdbc(hive)\nshow create table bike_trips","dateUpdated":"2017-08-11T13:43:47+0000","dateFinished":"2017-08-11T13:43:48+0000","dateStarted":"2017-08-11T13:43:47+0000","errorMessage":""},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{"0":{"graph":{"mode":"pieChart","height":300,"optionOpen":false},"helium":{}}},"editorSetting":{"language":"text","editOnDblClick":false},"editorMode":"ace/mode/text","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1502458950569_2138844845","id":"20170811-134230_836345512","dateCreated":"2017-08-11T13:42:30+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2953","text":"%jdbc(hive)\n\nselect \n case when a.gender=1 then 'Male' when a.gender=2 then 'Female' else 'Unknown' end gender,  a.trip_count \nfrom (select gender, count(*) trip_count from bike_trips\ngroup by gender) a","dateUpdated":"2017-08-11T13:51:47+0000","dateFinished":"2017-08-11T13:51:56+0000","dateStarted":"2017-08-11T13:51:47+0000","errorMessage":"","title":"Query to show Data as a Pie Chart (Riders by Gender)"},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"multiBarChart":{"stacked":true}},"commonSetting":{},"keys":[{"name":"dayofweek","index":1,"aggr":"sum"}],"groups":[{"name":"gender","index":0,"aggr":"sum"}],"values":[{"name":"_c2","index":2,"aggr":"sum"}]},"helium":{}}},"editorSetting":{"language":"text","editOnDblClick":false},"editorMode":"ace/mode/text","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1502458965360_-919124089","id":"20170811-134245_904971270","dateCreated":"2017-08-11T13:42:45+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3009","text":"%jdbc(hive)\n\nselect gender, dayofweek, count(*)\nfrom (    select date_format(`StartTime`,\"E\") dayofweek,\n          case when gender=1 then 'Male' when gender=2 then 'Female' else 'Unknown' end gender \nfrom bike_trips) bike_times \ngroup by gender, dayofweek","dateUpdated":"2017-08-11T13:46:51+0000","dateFinished":"2017-08-11T13:45:14+0000","dateStarted":"2017-08-11T13:45:02+0000","errorMessage":"","title":"Query to Show a Chart with Stacks or Groupings (Riders by Gender by Day)"},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{"0":{"graph":{"mode":"stackedAreaChart","height":300,"optionOpen":false,"setting":{"stackedAreaChart":{"style":"stack"}},"commonSetting":{},"keys":[{"name":"age","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"number_trips","index":1,"aggr":"sum"}]},"helium":{}}},"editorSetting":{"language":"text","editOnDblClick":false},"editorMode":"ace/mode/text","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1502458975438_965006599","id":"20170811-134255_220668446","dateCreated":"2017-08-11T13:42:55+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3065","text":"%jdbc(hive)\n\nselect (2016 - a.birthyear) age, count(*) number_trips from bike_trips as a\nwhere birthyear is not null\ngroup by birthyear\n","dateUpdated":"2017-08-11T13:47:33+0000","dateFinished":"2017-08-11T13:47:04+0000","dateStarted":"2017-08-11T13:46:55+0000","errorMessage":"","title":"Hive Query to Show a Chart (Age Distribution)"},{"text":"%md\n# Next Steps\n\nSo far, we\n\n1) have downloaded a Citi Bike data zip and created csv files. Then we stored the data into the Object Storage. \n2) set up a Hive table using the Hive command line\n3) queried Hive via Zepellin's JDBC(Hive) Interpreter\n\nIn the next tutorial we use Spark for processing and query. ","dateUpdated":"2017-08-11T13:48:11+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":"true"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Next Steps</h1>\n<p>So far, we</p>\n<p>1) have downloaded a Citi Bike data zip and created csv files. Then we stored the data into the Object Storage.<br/>2) set up a Hive table using the Hive command line<br/>3) queried Hive via Zepellin&rsquo;s JDBC(Hive) Interpreter</p>\n<p>In the next tutorial we use Spark for processing and query.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1502453027895_-1137918089","id":"20170512-090716_2012584955","dateCreated":"2017-08-11T12:03:47+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1326","user":"anonymous","dateFinished":"2017-08-11T13:48:11+0000","dateStarted":"2017-08-11T13:48:11+0000"},{"text":"%md\n### Tip: Running Hive and Zeppelin/Spark on a 2 OCPUs instance\n\nSome of you may be running this tutorial on the smallest configuration size (2 OCPUs).  If you are using this small shape, there can be scenarios where your Hive commands get \"Accepted\" but do not progress to \"Processing\".  You can see this behavior in the Jobs tab.  If this happens, then your Hive commands will hang indefinitely.  The reason this happens is that with 2 OCPUs, all of the available processing threads in the YARN resource manager can be occupied by other jobs.  There is a simple solution if you see this happen:  simply go to the Jobs tab, find the \"Zeppelin\" job, and abort it.  You will find that your Hive job will then move from \"Accepted\" to \"Processing\" and then finish.  The \"Zeppelin\" job will relaunch itself automatically the next time you run something with the Spark Interpreter inside Zeppelin.\n\nAn alternate solution is to add another node to your BDCS-CE cluster.  BDCS-CE is scalable, so you can add a node which will provide additional processing threads for YARN to work with.  You can also drop the node later if you want.","dateUpdated":"2017-08-11T12:03:47+0000","config":{"tableHide":false,"editorSetting":{"editOnDblClick":"true","language":"markdown"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Tip: Running Hive and Zeppelin/Spark on a 2 OCPUs instance</h3>\n<p>Some of you may be running this tutorial on the smallest configuration size (2 OCPUs). If you are using this small shape, there can be scenarios where your Hive commands get &ldquo;Accepted&rdquo; but do not progress to &ldquo;Processing&rdquo;. You can see this behavior in the Jobs tab. If this happens, then your Hive commands will hang indefinitely. The reason this happens is that with 2 OCPUs, all of the available processing threads in the YARN resource manager can be occupied by other jobs. There is a simple solution if you see this happen: simply go to the Jobs tab, find the &ldquo;Zeppelin&rdquo; job, and abort it. You will find that your Hive job will then move from &ldquo;Accepted&rdquo; to &ldquo;Processing&rdquo; and then finish. The &ldquo;Zeppelin&rdquo; job will relaunch itself automatically the next time you run something with the Spark Interpreter inside Zeppelin.</p>\n<p>An alternate solution is to add another node to your BDCS-CE cluster. BDCS-CE is scalable, so you can add a node which will provide additional processing threads for YARN to work with. You can also drop the node later if you want.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1502453027895_-1137918089","id":"20170512-135634_1459754506","dateCreated":"2017-08-11T12:03:47+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1327"},{"text":"%md\n### Change Log\nAugust 11, 2017 - Journey v2\nJuly 28, 2017 - Confirmed that it works on 17.3.1-20","dateUpdated":"2017-08-11T13:48:39+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":"true"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Change Log</h3>\n<p>August 11, 2017 - Journey v2<br/>July 28, 2017 - Confirmed that it works on 17.3.1-20</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1502453027896_-1139841834","id":"20170616-134351_1883942168","dateCreated":"2017-08-11T12:03:47+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1328","user":"anonymous","dateFinished":"2017-08-11T13:48:39+0000","dateStarted":"2017-08-11T13:48:39+0000"},{"text":"%md\n","dateUpdated":"2017-08-11T12:03:47+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","results":{},"enabled":true,"editorSetting":{"language":"markdown","editOnDblClick":"true"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1502453027896_-1139841834","id":"20170728-130618_1284552180","dateCreated":"2017-08-11T12:03:47+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1329"}],"name":"Tutorial 3 Working with Hive","id":"2CRQHFYEC","angularObjects":{"2CQV2CBDJ:shared_process":[],"2CSEK8ZNM:shared_process":[],"2CR6M4PTD:shared_process":[],"2CPFF54HX:shared_process":[],"2CSTM8NSJ:shared_process":[],"2CQ7GW4U4:shared_process":[],"2CT3QR1E8:shared_process":[],"2C4U48MY3_spark2:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}