{"paragraphs":[{"text":"%md\n# xtra Tutorial: Working with Oracle Database\n\nThis tutorial was built for BDCS-CE version 17.3.3-20 as part of the New Data Lake User Journey: <a href=\"https://github.com/oracle/learning-library/tree/master/workshops/journey2-new-data-lake\" target=\"_blank\">here</a>.  Questions and feedback about the tutorial: <david.bayard@oracle.com>\n\n\nContents\n\n + Setting up your Oracle Datbase Cloud Service for access from BDCS-CE\n + Using the Zeppelin JDBC Interpreter to query the Oracle Database\n + Examples with the JDBC Interpreter\n + Using Spark to query the Oracle Database\n + Examples with Spark SQL\n + Using Spark to write to the Oracle Database\n + Examples writting to the Oracle Database\n\n","user":"anonymous","dateUpdated":"2017-08-13T17:39:21+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true,"editorSetting":{"editOnDblClick":"true","language":"markdown"},"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>xtra Tutorial: Working with Oracle Database</h1>\n<p>This tutorial was built for BDCS-CE version 17.3.3-20 as part of the New Data Lake User Journey: <a href=\"https://github.com/oracle/learning-library/tree/master/workshops/journey2-new-data-lake\" target=\"_blank\">here</a>. Questions and feedback about the tutorial: <a href=\"mailto:&#100;a&#x76;i&#100;&#46;b&#x61;&#x79;&#x61;&#114;&#100;@&#111;&#114;&#x61;c&#108;&#101;&#46;&#x63;&#111;m\">&#100;a&#x76;i&#100;&#46;b&#x61;&#x79;&#x61;&#114;&#100;@&#111;&#114;&#x61;c&#108;&#101;&#46;&#x63;&#111;m</a></p>\n<p>Contents</p>\n<ul>\n  <li>Setting up your Oracle Datbase Cloud Service for access from BDCS-CE</li>\n  <li>Using the Zeppelin JDBC Interpreter to query the Oracle Database</li>\n  <li>Examples with the JDBC Interpreter</li>\n  <li>Using Spark to query the Oracle Database</li>\n  <li>Examples with Spark SQL</li>\n  <li>Using Spark to write to the Oracle Database</li>\n  <li>Examples writting to the Oracle Database</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1502645867918_1469236846","id":"20170414-115315_151675592","dateCreated":"2017-08-13T17:37:47+0000","dateStarted":"2017-08-13T17:39:21+0000","dateFinished":"2017-08-13T17:39:21+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:391"},{"text":"%md\n# Setting up your Oracle Datbase Cloud Service for access from BDCS-CE\n\nThis tutorial will assume you are using an Oracle Database running in the Oracle Database Cloud Service.  To connect from BDCS-CE, we need to:\n\n + Identify the database connect string (which embeds the database hostname and service name)\n + Ensure that an Access Rule allows network traffic from BDCS-CE to the Database server\n\nReview the Oracle Database Cloud - Database as a Service Quick Start: <http://www.oracle.com/webfolder/technetwork/tutorials/obe/cloud/dbaas/obe_dbaas_QS/oracle_database_cloud_service_dbaas_quick_start.html> .  Focus on the \"Finding the Connection Details for your Database Instance\" topic.\n\nFollow these steps (hint: you might want to open another browser window so you can keep these instructions open):\n\n + Navigate to the Oracle Database Cloud Service page for your DBCS instance.\n + Click on the Connect String to see the full value, highlight the full connect string, copy it into the clipboard, and save it somewhere for later use.\n![DBCS](https://raw.githubusercontent.com/oracle/learning-library/master/workshops/journey2-new-data-lake/images/600/DBCSconnectstring.gif \"DBCS\")\n\n \nNote: If you defined an Association between your BDCS-CE instance and your DBCS database when you created your BDCS-CE instance, then you should have the right network access rules already setup to communicate between BDCS-CE.  Most likely, you probably did NOT define an association between your DBCS database and your BDCS-CE instance when you provisioned the BDCS-CE instance.  Therefore, you will probably need to open up port 1521 on the DBCS instance for your BDCS-CE instance.\n\nInstructions can be found here: <https://docs.oracle.com/en/cloud/paas/database-dbaas-cloud/csdbi/enable-access-port.html>.  Here is an animation showing how to do it.\n![DBCS2](https://raw.githubusercontent.com/oracle/learning-library/master/workshops/journey2-new-data-lake/images/600/DBCSaccess.gif \"DBCS2\")\n\n","user":"anonymous","dateUpdated":"2017-08-13T17:39:33+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true,"editorSetting":{"editOnDblClick":"true","language":"markdown"},"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Setting up your Oracle Datbase Cloud Service for access from BDCS-CE</h1>\n<p>This tutorial will assume you are using an Oracle Database running in the Oracle Database Cloud Service. To connect from BDCS-CE, we need to:</p>\n<ul>\n  <li>Identify the database connect string (which embeds the database hostname and service name)</li>\n  <li>Ensure that an Access Rule allows network traffic from BDCS-CE to the Database server</li>\n</ul>\n<p>Review the Oracle Database Cloud - Database as a Service Quick Start: <a href=\"http://www.oracle.com/webfolder/technetwork/tutorials/obe/cloud/dbaas/obe_dbaas_QS/oracle_database_cloud_service_dbaas_quick_start.html\">http://www.oracle.com/webfolder/technetwork/tutorials/obe/cloud/dbaas/obe_dbaas_QS/oracle_database_cloud_service_dbaas_quick_start.html</a> . Focus on the &ldquo;Finding the Connection Details for your Database Instance&rdquo; topic.</p>\n<p>Follow these steps (hint: you might want to open another browser window so you can keep these instructions open):</p>\n<ul>\n  <li>Navigate to the Oracle Database Cloud Service page for your DBCS instance.</li>\n  <li>Click on the Connect String to see the full value, highlight the full connect string, copy it into the clipboard, and save it somewhere for later use.<br/><img src=\"https://raw.githubusercontent.com/oracle/learning-library/master/workshops/journey2-new-data-lake/images/600/DBCSconnectstring.gif\" alt=\"DBCS\" title=\"DBCS\" /></li>\n</ul>\n<p>Note: If you defined an Association between your BDCS-CE instance and your DBCS database when you created your BDCS-CE instance, then you should have the right network access rules already setup to communicate between BDCS-CE. Most likely, you probably did NOT define an association between your DBCS database and your BDCS-CE instance when you provisioned the BDCS-CE instance. Therefore, you will probably need to open up port 1521 on the DBCS instance for your BDCS-CE instance.</p>\n<p>Instructions can be found here: <a href=\"https://docs.oracle.com/en/cloud/paas/database-dbaas-cloud/csdbi/enable-access-port.html\">https://docs.oracle.com/en/cloud/paas/database-dbaas-cloud/csdbi/enable-access-port.html</a>. Here is an animation showing how to do it.<br/><img src=\"https://raw.githubusercontent.com/oracle/learning-library/master/workshops/journey2-new-data-lake/images/600/DBCSaccess.gif\" alt=\"DBCS2\" title=\"DBCS2\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1502645867919_1468852097","id":"20170504-100100_110721875","dateCreated":"2017-08-13T17:37:47+0000","dateStarted":"2017-08-13T17:39:31+0000","dateFinished":"2017-08-13T17:39:31+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:392"},{"text":"%md\n# Using the Zeppelin JDBC Interpreter to query the Oracle Database\n\nNow that you know the Connect String for your database, we can configure the JDBC Interpreter in Zeppelin.  To do so, follow these steps (Hint: you may want to open up a new browser window so you can keep these instructions open)\n\n + Click on the Settings tab in your BDCS-CE Console\n + Click on Notebook in the left-hand column\n + Scroll down and click on Edit for the JDBC Interpreter section\n + Fill in the user and password fields appropriately\n + For the url, enter: jdbc:oracle:thin:@// followed by the connect string you copied and saved from above.\n + For the driver, enter: oracle.jdbc.OracleDriver\n + Then click Save\n![jdbc](https://gse00010212.storage.oraclecloud.com/v1/Storage-gse00010212/images/snap0011635.jpg \"JDBC\")\n\n\nAt this point, you can start using paragraphs with the %jdbc Interpreter.\n\n","user":"anonymous","dateUpdated":"2017-08-13T17:40:11+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true,"editorSetting":{"editOnDblClick":"true","language":"markdown"},"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Using the Zeppelin JDBC Interpreter to query the Oracle Database</h1>\n<p>Now that you know the Connect String for your database, we can configure the JDBC Interpreter in Zeppelin. To do so, follow these steps (Hint: you may want to open up a new browser window so you can keep these instructions open)</p>\n<ul>\n  <li>Click on the Settings tab in your BDCS-CE Console</li>\n  <li>Click on Notebook in the left-hand column</li>\n  <li>Scroll down and click on Edit for the JDBC Interpreter section</li>\n  <li>Fill in the user and password fields appropriately</li>\n  <li>For the url, enter: jdbc:oracle:thin:@// followed by the connect string you copied and saved from above.</li>\n  <li>For the driver, enter: oracle.jdbc.OracleDriver</li>\n  <li>Then click Save<br/><img src=\"https://gse00010212.storage.oraclecloud.com/v1/Storage-gse00010212/images/snap0011635.jpg\" alt=\"jdbc\" title=\"JDBC\" /></li>\n</ul>\n<p>At this point, you can start using paragraphs with the %jdbc Interpreter.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1502645867919_1468852097","id":"20170414-115328_1407983634","dateCreated":"2017-08-13T17:37:47+0000","dateStarted":"2017-08-13T17:40:11+0000","dateFinished":"2017-08-13T17:40:11+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:393"},{"title":"Another example","text":"%jdbc\nselect table_name from user_tables","user":"anonymous","dateUpdated":"2017-08-13T18:01:18+0000","config":{"colWidth":4,"editorMode":"ace/mode/sql","title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[{"name":"TABLE_NAME","index":0,"aggr":"sum"}],"values":[],"groups":[],"scatter":{"xAxis":{"name":"TABLE_NAME","index":0,"aggr":"sum"}}}}],"enabled":true,"editorSetting":{"editOnDblClick":"false","language":"sql"},"editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"java.lang.ClassNotFoundException: oracle.jdbc.OracleDriver\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:381)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n\tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:335)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n\tat java.lang.Class.forName0(Native Method)\n\tat java.lang.Class.forName(Class.java:264)\n\tat org.apache.zeppelin.jdbc.JDBCInterpreter.createConnectionPool(JDBCInterpreter.java:341)\n\tat org.apache.zeppelin.jdbc.JDBCInterpreter.getConnectionFromPool(JDBCInterpreter.java:352)\n\tat org.apache.zeppelin.jdbc.JDBCInterpreter.getConnection(JDBCInterpreter.java:372)\n\tat org.apache.zeppelin.jdbc.JDBCInterpreter.executeSql(JDBCInterpreter.java:564)\n\tat org.apache.zeppelin.jdbc.JDBCInterpreter.interpret(JDBCInterpreter.java:692)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.interpret(LazyOpenInterpreter.java:94)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:489)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:175)\n\tat org.apache.zeppelin.scheduler.ParallelScheduler$JobRunner.run(ParallelScheduler.java:162)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:748)\n"}]},"apps":[],"jobName":"paragraph_1502645867920_1479240317","id":"20170504-132054_979805353","dateCreated":"2017-08-13T17:37:47+0000","dateStarted":"2017-08-13T18:01:18+0000","dateFinished":"2017-08-13T18:01:18+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:394"},{"title":"JDBC Interpreter in action","text":"%jdbc\nselect * from emp","user":"anonymous","dateUpdated":"2017-08-13T18:01:22+0000","config":{"colWidth":8,"editorMode":"ace/mode/sql","title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[{"name":"EMPNO","index":0,"aggr":"sum"}],"values":[{"name":"ENAME","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"EMPNO","index":0,"aggr":"sum"},"yAxis":{"name":"ENAME","index":1,"aggr":"sum"}}}}],"enabled":true,"editorSetting":{"editOnDblClick":"false","language":"sql"},"editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"java.lang.ClassNotFoundException: oracle.jdbc.OracleDriver\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:381)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n\tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:335)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n\tat java.lang.Class.forName0(Native Method)\n\tat java.lang.Class.forName(Class.java:264)\n\tat org.apache.zeppelin.jdbc.JDBCInterpreter.createConnectionPool(JDBCInterpreter.java:341)\n\tat org.apache.zeppelin.jdbc.JDBCInterpreter.getConnectionFromPool(JDBCInterpreter.java:352)\n\tat org.apache.zeppelin.jdbc.JDBCInterpreter.getConnection(JDBCInterpreter.java:372)\n\tat org.apache.zeppelin.jdbc.JDBCInterpreter.executeSql(JDBCInterpreter.java:564)\n\tat org.apache.zeppelin.jdbc.JDBCInterpreter.interpret(JDBCInterpreter.java:692)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.interpret(LazyOpenInterpreter.java:94)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:489)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:175)\n\tat org.apache.zeppelin.scheduler.ParallelScheduler$JobRunner.run(ParallelScheduler.java:162)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:748)\n"}]},"apps":[],"jobName":"paragraph_1502645867920_1479240317","id":"20170414-115717_230408128","dateCreated":"2017-08-13T17:37:47+0000","dateStarted":"2017-08-13T18:01:22+0000","dateFinished":"2017-08-13T18:01:22+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:395"},{"text":"%jdbc\nselect deptno, count(*) from emp group by deptno","dateUpdated":"2017-08-13T17:37:47+0000","config":{"colWidth":12,"editorMode":"ace/mode/sql","results":[{"graph":{"mode":"pieChart","height":300,"optionOpen":false,"keys":[{"name":"DEPTNO","index":0,"aggr":"sum"}],"values":[{"name":"COUNT(*)","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"DEPTNO","index":0,"aggr":"sum"},"yAxis":{"name":"COUNT(*)","index":1,"aggr":"sum"}}}}],"enabled":true,"editorSetting":{"editOnDblClick":"false","language":"sql"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"DEPTNO\tCOUNT(*)\n30\t6\n20\t5\n10\t3\n"}]},"apps":[],"jobName":"paragraph_1502645867921_1478855569","id":"20170504-132141_1183948525","dateCreated":"2017-08-13T17:37:47+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:396"},{"text":"%md\n#Using Spark to query the Oracle Database\n\nIn this section of the tutorial, we will show you working code examples that define a Spark Dataframe as an Oracle SQL query.  We then define a Spark SQL temporary table against that Dataframe to show you how you can futher use Spark SQL to filter and manipulate your selected data.\n\nTo run the spark code, you should first edit the code and insert your specific database connect string, username, and password.\n\n\n\nTo learn more about how Spark Data Frames work with JDBC data sources, check out <https://spark.apache.org/docs/1.6.1/sql-programming-guide.html#jdbc-to-other-databases> .\n\n\n\n\n","dateUpdated":"2017-08-13T17:37:47+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true,"editorSetting":{}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Using Spark to query the Oracle Database</h1>\n<p>In this section of the tutorial, we will show you working code examples that define a Spark Dataframe as an Oracle SQL query.  We then define a Spark SQL temporary table against that Dataframe to show you how you can futher use Spark SQL to filter and manipulate your selected data.</p>\n<p>To run the spark code, you should first edit the code and insert your specific database connect string, username, and password.</p>\n<p>To learn more about how Spark Data Frames work with JDBC data sources, check out <a href=\"https://spark.apache.org/docs/1.6.1/sql-programming-guide.html#jdbc-to-other-databases\">https://spark.apache.org/docs/1.6.1/sql-programming-guide.html#jdbc-to-other-databases</a> .</p>\n"}]},"apps":[],"jobName":"paragraph_1502645867921_1478855569","id":"20170414-115733_409524242","dateCreated":"2017-08-13T17:37:47+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:397"},{"title":"Spark code to query the Oracle Database and define results and Spark SQL tables","text":"%spark\n\n// BEFORE RUNNING THIS, YOU WILL NEED TO EDIT THIS\n//  1.Insert your database Connect String\n//  2.Insert your database user name\n//  3.Insert your database password\n\n\n//define URL for the Oracle JDBC driver\nprintln(\">>>>>>>Defining url for Oracle JDBC\")\nval url=\"jdbc:oracle:thin:@//\" + \"CD-DBCS-ORCL12:1521/PDB1.gse00010212.oraclecloud.internal\"\n\n//define the username and password as properties\nprintln(\">>>>>>>Defining Oracle JDBC username and password\")\nval prop = new java.util.Properties\nprop.setProperty(\"user\",\"scott\")\nprop.setProperty(\"password\",\"tiger\")\nprop.setProperty(\"driver\",\"oracle.jdbc.OracleDriver\") //the driver is needed to be defined with Spark 1.6.1 due to https://issues.apache.org/jira/browse/SPARK-14204\n\n//now you can use JDBC commands like: val movies = sqlContext.read.jdbc(url,\"movie\",prop)\nval emp = sqlContext.read.jdbc(url,\"emp\",prop)\n//emp.explain()\nemp.printSchema()\nemp.show()\n\n//register the emp dataframe as a SparkSQL table\nemp.registerTempTable(\"emp_sparksql\")\n\n//we can also do specific queries like the following (note that we write our query as if it was a subquery in the FROM section of a select statement)\nval emp_query = sqlContext.read.jdbc(url, \"(select e.deptno, d.dname, count(*) dcount from emp e, dept d where e.deptno=d.deptno group by e.deptno, d.dname) eq\", prop)\nemp_query.show()\n//emp_query.explain()\n\nprintln(\"done\")","user":"anonymous","dateUpdated":"2017-08-13T18:01:36+0000","config":{"tableHide":false,"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1502645867921_1478855569","id":"20170414-115750_30775030","dateCreated":"2017-08-13T17:37:47+0000","dateStarted":"2017-08-13T18:01:37+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:398","dateFinished":"2017-08-13T18:05:20+0000","results":{"code":"ERROR","msg":[{"type":"TEXT","data":">>>>>>>Defining url for Oracle JDBC\n\nurl: String = jdbc:oracle:thin:@//CD-DBCS-ORCL12:1521/PDB1.gse00010212.oraclecloud.internal\n>>>>>>>Defining Oracle JDBC username and password\n\nprop: java.util.Properties = {}\n\nres3: Object = null\n\nres4: Object = null\n\nres5: Object = null\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\njava.sql.SQLRecoverableException: IO Error: Unknown host specified\n  at oracle.jdbc.driver.T4CConnection.logon(T4CConnection.java:743)\n  at oracle.jdbc.driver.PhysicalConnection.connect(PhysicalConnection.java:666)\n  at oracle.jdbc.driver.T4CDriverExtension.getConnection(T4CDriverExtension.java:32)\n  at oracle.jdbc.driver.OracleDriver.connect(OracleDriver.java:566)\n  at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anonfun$createConnectionFactory$1.apply(JdbcUtils.scala:59)\n  at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anonfun$createConnectionFactory$1.apply(JdbcUtils.scala:50)\n  at org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.resolveTable(JDBCRDD.scala:58)\n  at org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation.<init>(JDBCRelation.scala:113)\n  at org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:45)\n  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:330)\n  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)\n  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:125)\n  at org.apache.spark.sql.DataFrameReader.jdbc(DataFrameReader.scala:166)\n  ... 46 elided\nCaused by: oracle.net.ns.NetException: Unknown host specified\n  at oracle.net.resolver.HostnameNamingAdapter.resolve(HostnameNamingAdapter.java:207)\n  at oracle.net.resolver.NameResolver.resolveName(NameResolver.java:131)\n  at oracle.net.resolver.AddrResolution.resolveAndExecute(AddrResolution.java:476)\n  at oracle.net.ns.NSProtocol.establishConnection(NSProtocol.java:595)\n  at oracle.net.ns.NSProtocol.connect(NSProtocol.java:230)\n  at oracle.jdbc.driver.T4CConnection.connect(T4CConnection.java:1452)\n  at oracle.jdbc.driver.T4CConnection.logon(T4CConnection.java:496)\n  ... 58 more\n"}]}},{"title":"SparkSQL Example against our Oracle Database-based Data Frame","text":"%sql\nselect * from emp_sparksql\nwhere deptno=10","dateUpdated":"2017-08-13T17:37:47+0000","config":{"colWidth":12,"title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[{"name":"EMPNO","index":0,"aggr":"sum"}],"values":[{"name":"ENAME","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"EMPNO","index":0,"aggr":"sum"},"yAxis":{"name":"ENAME","index":1,"aggr":"sum"}}}}],"enabled":true,"editorSetting":{"language":"sql"},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"EMPNO\tENAME\tJOB\tMGR\tHIREDATE\tSAL\tCOMM\tDEPTNO\n7782\tCLARK\tMANAGER\t7839\t1981-06-09 00:00:00.0\t2450.00\tnull\t10\n7839\tKING\tPRESIDENT\tnull\t1981-11-17 00:00:00.0\t5000.00\tnull\t10\n7934\tMILLER\tCLERK\t7782\t1982-01-23 00:00:00.0\t1300.00\tnull\t10\n"}]},"apps":[],"jobName":"paragraph_1502645867922_1480009815","id":"20170414-120105_774930594","dateCreated":"2017-08-13T17:37:47+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:399"},{"text":"%md\n#Using Spark to write to the Oracle Database\n\nNow we will show a working example of writing back to the Oracle Database from Spark.  If you observed above, we created a Spark dataframe called emp_query.  In the following example, we will write this dataframe back to the Oracle Database as a new table called emp_query.\n\nWith Spark 1.6.1, there are a few issues with Spark's ability to generate valid Oracle datatypes for use with Oracle create table statements.  Our example will implement a hot-fix that provides a better OracleDialect than what comes with Spark 1.6.1 itself in order to fix these datatype issues.\n\n\n","dateUpdated":"2017-08-13T17:37:47+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true,"editorSetting":{"editOnDblClick":"true","language":"markdown"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Using Spark to write to the Oracle Database</h1>\n<p>Now we will show a working example of writing back to the Oracle Database from Spark.  If you observed above, we created a Spark dataframe called emp_query.  In the following example, we will write this dataframe back to the Oracle Database as a new table called emp_query.</p>\n<p>With Spark 1.6.1, there are a few issues with Spark's ability to generate valid Oracle datatypes for use with Oracle create table statements.  Our example will implement a hot-fix that provides a better OracleDialect than what comes with Spark 1.6.1 itself in order to fix these datatype issues.</p>\n"}]},"apps":[],"jobName":"paragraph_1502645867922_1480009815","id":"20170504-134249_302037388","dateCreated":"2017-08-13T17:37:47+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:400"},{"title":"Spark code to write a dataframe to the Oracle Database","text":"%spark\n\nprintln(\">>>>>>>Setting up workaround for SPARK-12941, etc\")\n//based on http://stackoverflow.com/questions/31287182/writing-to-oracle-database-using-apache-spark-1-4-0\n\n  import org.apache.spark.sql.jdbc.{JdbcDialects, JdbcType, JdbcDialect}\n  import org.apache.spark.sql.types._\n  import java.sql.Types\n\n  val OracleDialect = new JdbcDialect {\n    override def canHandle(url: String): Boolean = url.startsWith(\"jdbc:oracle\") \n    \n    override def getCatalystType(\n      sqlType: Int, typeName: String, size: Int, md: MetadataBuilder): Option[DataType] = {\n    // Handle NUMBER fields that have no precision/scale in special way\n    // because JDBC ResultSetMetaData converts this to 0 procision and -127 scale\n    // For more details, please see\n    // https://github.com/apache/spark/pull/8780#issuecomment-145598968\n    // and\n    // https://github.com/apache/spark/pull/8780#issuecomment-144541760\n    if (sqlType == Types.NUMERIC && size == 0) {\n      // This is sub-optimal as we have to pick a precision/scale in advance whereas the data\n      //  in Oracle is allowed to have different precision/scale for each value.\n      Option(DecimalType(DecimalType.MAX_PRECISION, 10))\n    } else {\n      None\n    }\n    }\n\n   override def getJDBCType(dt: DataType): Option[JdbcType] = dt match {\n    // For more details, please see\n    // https://docs.oracle.com/cd/E19501-01/819-3659/gcmaz/\n    case BooleanType => Some(JdbcType(\"NUMBER(1)\", java.sql.Types.BOOLEAN))\n    case IntegerType => Some(JdbcType(\"NUMBER(10)\", java.sql.Types.INTEGER))\n    case LongType => Some(JdbcType(\"NUMBER(19)\", java.sql.Types.BIGINT))\n    case FloatType => Some(JdbcType(\"NUMBER(19, 4)\", java.sql.Types.FLOAT))\n    case DoubleType => Some(JdbcType(\"NUMBER(19, 4)\", java.sql.Types.DOUBLE))\n    case ByteType => Some(JdbcType(\"NUMBER(3)\", java.sql.Types.SMALLINT))\n    case ShortType => Some(JdbcType(\"NUMBER(5)\", java.sql.Types.SMALLINT))\n    case StringType => Some(JdbcType(\"VARCHAR2(255)\", java.sql.Types.VARCHAR))\n      case BinaryType => Some(JdbcType(\"BLOB\", java.sql.Types.BLOB))\n      case TimestampType => Some(JdbcType(\"DATE\", java.sql.Types.DATE))\n      case DateType => Some(JdbcType(\"DATE\", java.sql.Types.DATE))\n      case DecimalType.Unlimited => Some(JdbcType(\"NUMBER(38,4)\", java.sql.Types.NUMERIC))\n    case _ => None\n   }\n    \n\n  }\n\n  JdbcDialects.registerDialect(OracleDialect)\nprintln(\"Finised with workaround.\")\n\n\n// review our emp_query data_frame (created above)\nprintln(\"Reviewing our emp_query data frame...\")\nemp_query.show()\nemp_query.printSchema()\n\n\nimport org.apache.spark.sql.SaveMode\n//possible SaveModes are SaveMode.Append, SaveMode.Overwrite, SaveMode.ErrorIfExists, SaveMode.Ignore\n\n\nprintln(\"Writing Spark DataFrame to Oracle Database\")\nemp_query.write\n   .mode(SaveMode.Overwrite)\n   .jdbc(url,\"EMP_QUERY\",prop)\n\n\n//sometimes you might hit errors writing back to Oracle due to datatypes.  Here is how you can see the datatypes being generated for Oracle and look for issues\nimport org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils\nprintln(\"Generated Oracle Datatypes: \"+JdbcUtils.schemaString(emp_query, url))\n\n//your Spark dataframe needs to use valid Oracle column names (i.e. no spaces, no reserved words, etc).  If you need to rename dataframe fields, you can do operations like this\n//val newdDF=oldDF.withColumnRenamed(\"Birth Year\",\"BirthYear\")\n\n//unregister our custom Dialect just to be clean\nJdbcDialects.unregisterDialect(OracleDialect)\n\nprintln(\"done\")","dateUpdated":"2017-08-13T17:37:47+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":">>>>>>>Setting up workaround for SPARK-12941, etc\nimport org.apache.spark.sql.jdbc.{JdbcDialects, JdbcType, JdbcDialect}\nimport org.apache.spark.sql.types._\nimport java.sql.Types\nwarning: there were 1 deprecation warning(s); re-run with -deprecation for details\nOracleDialect: org.apache.spark.sql.jdbc.JdbcDialect = $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anon$1@673f7c9c\nFinised with workaround.\nReviewing our emp_query data frame...\n+------+----------+------------+\n|DEPTNO|     DNAME|      DCOUNT|\n+------+----------+------------+\n|    10|ACCOUNTING|3.0000000000|\n|    20|  RESEARCH|5.0000000000|\n|    30|     SALES|6.0000000000|\n+------+----------+------------+\n\nroot\n |-- DEPTNO: decimal(2,0) (nullable = true)\n |-- DNAME: string (nullable = true)\n |-- DCOUNT: decimal(38,10) (nullable = true)\n\nimport org.apache.spark.sql.SaveMode\nWriting Spark DataFrame to Oracle Database\nimport org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils\nGenerated Oracle Datatypes: DEPTNO DECIMAL(2,0) , DNAME VARCHAR2(255) , DCOUNT DECIMAL(38,10) \ndone\n"}]},"apps":[],"jobName":"paragraph_1502645867922_1480009815","id":"20170504-134433_1223668517","dateCreated":"2017-08-13T17:37:47+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:401"},{"text":"%jdbc\nselect * from EMP_QUERY","dateUpdated":"2017-08-13T17:37:47+0000","config":{"colWidth":12,"editorMode":"ace/mode/sql","results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true,"editorSetting":{"editOnDblClick":"false","language":"sql"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"DEPTNO\tDNAME\tDCOUNT\n10\tACCOUNTING\t3\n20\tRESEARCH\t5\n30\tSALES\t6\n"}]},"apps":[],"jobName":"paragraph_1502645867923_1479625066","id":"20170504-145612_585260865","dateCreated":"2017-08-13T17:37:47+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:402"},{"dateUpdated":"2017-08-13T17:37:47+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1502645867923_1479625066","id":"20170414-131833_1025546137","dateCreated":"2017-08-13T17:37:47+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:403"}],"name":"xtra Working with Oracle Database","id":"2CRXUVR6R","angularObjects":{"2CRC61AHT:shared_process":[],"2CQ1XQM8K:shared_process":[],"2CQK65TXR:shared_process":[],"2CQ1R3AU6:shared_process":[],"2CTA4DVPB:shared_process":[],"2C4U48MY3_spark2:shared_process":[],"2CPK7VRBY:shared_process":[],"2CSBR581X:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}