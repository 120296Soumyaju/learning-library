{"paragraphs":[{"text":"%md\n# Tutorial 4-2: Extending your analysis with more datasets\n\nThis tutorial was built for BDCS-CE version 17.3.5-20 as part of the New Data Lake User Journey: <a href=\"https://github.com/oracle/learning-library/tree/master/workshops/journey2-new-data-lake\" target=\"_blank\">here</a>.  Questions and feedback about the tutorial: <david.bayard@oracle.com>\n\n    Be sure you previously ran the Tutorial: \"Working with the Spark Interpreter\"\n\nThis tutorial will add some additional datasets (weather and holidays) to combine with our bike trip data.\n\n## Contents\n\n+ Fill this in later\n\nAs a reminder, the documentation for BDCS-CE can be found: <a href=\"http://docs.oracle.com/cloud/latest/big-data-compute-cloud/index.html\" target=\"_blank\">here</a>","user":"anonymous","dateUpdated":"2017-10-06T12:36:03+0000","config":{"tableHide":false,"editorSetting":{"editOnDblClick":"true","language":"markdown"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Tutorial 4-2: Extending your analysis with more datasets</h1>\n<p>This tutorial was built for BDCS-CE version 17.3.5-20 as part of the New Data Lake User Journey: <a href=\"https://github.com/oracle/learning-library/tree/master/workshops/journey2-new-data-lake\" target=\"_blank\">here</a>. Questions and feedback about the tutorial: <a href=\"mailto:&#100;&#97;&#118;&#x69;&#100;&#46;&#x62;&#97;&#x79;&#x61;&#x72;&#x64;&#64;&#x6f;&#114;&#97;c&#108;&#x65;&#x2e;c&#x6f;&#109;\">&#100;&#97;&#118;&#x69;&#100;&#46;&#x62;&#97;&#x79;&#x61;&#x72;&#x64;&#64;&#x6f;&#114;&#97;c&#108;&#x65;&#x2e;c&#x6f;&#109;</a></p>\n<pre><code>Be sure you previously ran the Tutorial: &quot;Working with the Spark Interpreter&quot;\n</code></pre>\n<p>This tutorial will add some additional datasets (weather and holidays) to combine with our bike trip data.</p>\n<h2>Contents</h2>\n<ul>\n  <li>Fill this in later</li>\n</ul>\n<p>As a reminder, the documentation for BDCS-CE can be found: <a href=\"http://docs.oracle.com/cloud/latest/big-data-compute-cloud/index.html\" target=\"_blank\">here</a></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1507291908122_-1231947890","id":"20170414-131903_889251720","dateCreated":"2017-10-06T12:11:48+0000","dateStarted":"2017-10-06T12:19:36+0000","dateFinished":"2017-10-06T12:19:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1188"},{"text":"%md\n# Requesting free Weather Data from the Government\n\nIn this tutorial, we will add some weather data to our data lake.  We will use the US Government's National Center for Environmental Information website to request the daily weather summary for New York City for December 2016 (the same time frame as our bike data).  We will use the website to request/order the weather data and then we download the data once the request is ready.\n\n![CDO](https://raw.githubusercontent.com/oracle/learning-library/master/workshops/journey2-new-data-lake/images/300/snap0012665.jpg)\n\n\nTo get our weather data, follow these steps: (if you are in a hurry, you can skip below to the paragraph titled \"If you are in a hurry...\")\n\n+ Open a browser to the Climate Data Online website, run by the US Government: <a href=\"https://www.ncdc.noaa.gov/cdo-web/\" target=\"_blank\">https ://www.ncdc.noaa.gov/cdo-web/</a>\n+ Click on Search Tool\n+ Choose:\nDaily Summaries\n2016-12-01 to 2016-12-31\nCites\nNew York City\n+ Click the \"ADD TO CART\" button for the \"New York, NY US\" row.\n+ Navigate to the \"Cart (Free Data) 1 item\" area and click \"View All Items(1)\"\n+ Choose Custom GHCN-Daily CSV and click Continue\n+ In the \"Select data types for custom output\" section, click \"Show All\".  Then select\nPRCP - Precipitation\nSNWD - Snow depth \nSNOW - Snowfall\nTAVG - Average Temperature.\nTMAX - Maximum temperature\nTMIN - Minimum temperature\nAWND - Average wind speed\n+ Click Continue\n+ Enter your email address and click Submit Order\n\nGood job!  Now get yourself a cup a coffee as it may take a few minutes for your order to work through the queue.\n\n","user":"anonymous","dateUpdated":"2017-10-06T13:11:01+0000","config":{"tableHide":false,"editorSetting":{"editOnDblClick":"true","language":"markdown"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Requesting free Weather Data from the Government</h1>\n<p>In this tutorial, we will add some weather data to our data lake. We will use the US Government&rsquo;s National Center for Environmental Information website to request the daily weather summary for New York City for December 2016 (the same time frame as our bike data). We will use the website to request/order the weather data and then we download the data once the request is ready.</p>\n<p><img src=\"https://raw.githubusercontent.com/oracle/learning-library/master/workshops/journey2-new-data-lake/images/300/snap0012665.jpg\" alt=\"CDO\" /></p>\n<p>To get our weather data, follow these steps: (if you are in a hurry, you can skip below to the paragraph titled &ldquo;If you are in a hurry&hellip;&rdquo;)</p>\n<ul>\n  <li>Open a browser to the Climate Data Online website, run by the US Government: <a href=\"https://www.ncdc.noaa.gov/cdo-web/\" target=\"_blank\">https ://www.ncdc.noaa.gov/cdo-web/</a></li>\n  <li>Click on Search Tool</li>\n  <li>Choose:<br/>Daily Summaries<br/>2016-12-01 to 2016-12-31<br/>Cites<br/>New York City</li>\n  <li>Click the &ldquo;ADD TO CART&rdquo; button for the &ldquo;New York, NY US&rdquo; row.</li>\n  <li>Navigate to the &ldquo;Cart (Free Data) 1 item&rdquo; area and click &ldquo;View All Items(1)&rdquo;</li>\n  <li>Choose Custom GHCN-Daily CSV and click Continue</li>\n  <li>In the &ldquo;Select data types for custom output&rdquo; section, click &ldquo;Show All&rdquo;. Then select<br/>PRCP - Precipitation<br/>SNWD - Snow depth<br/>SNOW - Snowfall<br/>TAVG - Average Temperature.<br/>TMAX - Maximum temperature<br/>TMIN - Minimum temperature<br/>AWND - Average wind speed</li>\n  <li>Click Continue</li>\n  <li>Enter your email address and click Submit Order</li>\n</ul>\n<p>Good job! Now get yourself a cup a coffee as it may take a few minutes for your order to work through the queue.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1507291908123_-1232332639","id":"20170616-103849_1176559517","dateCreated":"2017-10-06T12:11:48+0000","dateStarted":"2017-10-06T13:11:01+0000","dateFinished":"2017-10-06T13:11:01+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1189"},{"text":"%md\n# Downloading, Uploading the weather data when the request is ready\n\nA few minutes after submiting your free order for weather data, you should receive an email indicating that your Order is complete.\n\n+ Click on the Order ID link in the email.  This will take you to the Order History page\n+ Right-click on the download button and choose Copy Link Location\n+ Paste the value into the weather data URL input field in the paragraph below, then run the paragraph below\n\n\n","user":"anonymous","dateUpdated":"2017-10-06T13:00:56+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":"true"},"editorMode":"ace/mode/markdown","editorHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Downloading, Uploading the weather data when the request is ready</h1>\n<p>A few minutes after submiting your free order for weather data, you should receive an email indicating that your Order is complete.</p>\n<ul>\n  <li>Click on the Order ID link in the email. This will take you to the Order History page</li>\n  <li>Right-click on the download button and choose Copy Link Location</li>\n  <li>Paste the value into the weather data URL input field in the paragraph below, then run the paragraph below</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1507293943742_230762327","id":"20171006-124543_574686421","dateCreated":"2017-10-06T12:45:43+0000","dateStarted":"2017-10-06T13:00:56+0000","dateFinished":"2017-10-06T13:00:56+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1190"},{"text":"%md\n## If you are in a hurry... (and don't want to order the government weather data yourself)\n\nCopy this value and paste it into the Weather_Data_URL input field below and run the paragraph.\n\n    https://raw.githubusercontent.com/oracle/learning-library/master/workshops/journey2-new-data-lake/files/1090166.csv\n    \n\n\n","user":"anonymous","dateUpdated":"2017-10-06T13:11:37+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":"true"},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>If you are in a hurry&hellip; (and don&rsquo;t want to order the government weather data yourself)</h2>\n<p>Copy this value and paste it into the Weather_Data_URL input field below and run the paragraph.</p>\n<pre><code>https://raw.githubusercontent.com/oracle/learning-library/master/workshops/journey2-new-data-lake/files/1090166.csv\n</code></pre>\n</div>"}]},"apps":[],"jobName":"paragraph_1507294356346_-779373746","id":"20171006-125236_974558193","dateCreated":"2017-10-06T12:52:36+0000","dateStarted":"2017-10-06T13:11:37+0000","dateFinished":"2017-10-06T13:11:37+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1191"},{"title":"Script to download weather data and upload to Object Store","text":"%sh\nCONTAINER=journeyC\nDIRECTORY=weather\nFILENAME=201612-weather\n\ntest -e $DIRECTORY || mkdir $DIRECTORY\ncd $DIRECTORY\nrm $FILENAME.csv\n\necho \"Downloading $FILENAME.csv.  This may take a minute.\"\nwget -O $FILENAME.csv ${Weather_Data_URL=https://raw.githubusercontent.com/oracle/learning-library/master/workshops/journey2-new-data-lake/files/1090166.csv}\necho \".\"\necho \".\"\necho \".\"\nls -ltr $FILENAME.csv\necho \".\"\necho \".\"\necho \".\"\n\necho \"Storing file to Object Storage.  This may take a few minutes.\"\n# we use the hadoop swift:// driver to interact with the Object Store.\n# The .default configuration of the swift driver is the object store connection you defined when you created the BDCSCE instance.\n\necho \"List the directory. directory should be empty or missing\"\nhadoop fs -ls swift://$CONTAINER.default/$DIRECTORY \necho \"Make the raw directory in Object Store\"\nhadoop fs -mkdir -p swift://$CONTAINER.default/$DIRECTORY/raw \necho \"Copy First File to Object Store. May take a minute\"\nhadoop fs -put $FILENAME.csv swift://$CONTAINER.default/$DIRECTORY/raw/$FILENAME.csv \necho \"Validate by listing the csv file that got copied to Object Store\"\nhadoop fs -ls swift://$CONTAINER.default/$DIRECTORY/raw \necho \".\"\necho \".\"\n\necho \"Quick glance at first few lines of weather file...\"\nhead $FILENAME.csv\necho \".\"\necho \".\"\necho \"done\"","user":"anonymous","dateUpdated":"2017-10-06T13:25:11+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":"false"},"editorMode":"ace/mode/sh","title":true,"editorHide":true,"tableHide":false},"settings":{"params":{"Weather_Data_URL":"https://www.ncei.noaa.gov/orders/cdo/1090166.csv"},"forms":{"Weather_Data_URL":{"name":"Weather_Data_URL","defaultValue":"https://raw.githubusercontent.com/oracle/learning-library/master/workshops/journey2-new-data-lake/files/1090166.csv","hidden":false,"$$hashKey":"object:3035"}}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Downloading 201612-weather.csv.  This may take a minute.\n--2017-10-06 13:25:11--  https://www.ncei.noaa.gov/orders/cdo/1090166.csv\nResolving www.ncei.noaa.gov... 205.167.25.172, 205.167.25.171, 2610:20:8040:2::172, ...\nConnecting to www.ncei.noaa.gov|205.167.25.172|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 259900 (254K) [text/csv]\nSaving to: “201612-weather.csv”\n\n     0K .......... .......... .......... .......... .......... 19%  190K 1s\n    50K .......... .......... .......... .......... .......... 39%  286K 1s\n   100K .......... .......... .......... .......... .......... 59%  572K 0s\n   150K .......... .......... .......... .......... .......... 78%  287K 0s\n   200K .......... .......... .......... .......... .......... 98%  573K 0s\n   250K ...                                                   100% 20.6M=0.8s\n\n2017-10-06 13:25:12 (323 KB/s) - “201612-weather.csv” saved [259900/259900]\n\n.\n.\n.\n-rw-rw-r-- 1 zeppelin zeppelin 259900 Oct  6 12:27 201612-weather.csv\n.\n.\n.\nStoring file to Object Storage.  This may take a few minutes.\nList the directory. directory should be empty or missing\nFound 1 items\ndrw-rw-rw-   -          0 2017-10-06 13:24 swift://journeyC.default/weather/raw\nMake the raw directory in Object Store\nCopy First File to Object Store. May take a minute\nput: `swift://journeyC.default/weather/raw/201612-weather.csv': File exists\nValidate by listing the csv file that got copied to Object Store\nFound 1 items\n-rw-rw-rw-   1     259900 2017-10-06 13:24 swift://journeyC.default/weather/raw/201612-weather.csv\n.\n.\nQuick glance at first few lines of weather file...\n\"STATION\",\"NAME\",\"LATITUDE\",\"LONGITUDE\",\"ELEVATION\",\"DATE\",\"AWND\",\"PRCP\",\"SNOW\",\"SNWD\",\"TAVG\",\"TMAX\",\"TMIN\"\n\"US1NYWC0003\",\"WHITE PLAINS 3.1 NNW, NY US\",\"41.0639\",\"-73.7722\",\"71.0\",\"2016-12-01\",,\"1.14\",,,,,\n\"US1NYWC0003\",\"WHITE PLAINS 3.1 NNW, NY US\",\"41.0639\",\"-73.7722\",\"71.0\",\"2016-12-02\",,\"0.00\",\"0.0\",,,,\n\"US1NYWC0003\",\"WHITE PLAINS 3.1 NNW, NY US\",\"41.0639\",\"-73.7722\",\"71.0\",\"2016-12-03\",,\"0.00\",\"0.0\",,,,\n\"US1NYWC0003\",\"WHITE PLAINS 3.1 NNW, NY US\",\"41.0639\",\"-73.7722\",\"71.0\",\"2016-12-04\",,\"0.00\",\"0.0\",,,,\n\"US1NYWC0003\",\"WHITE PLAINS 3.1 NNW, NY US\",\"41.0639\",\"-73.7722\",\"71.0\",\"2016-12-05\",,\"0.12\",,,,,\n\"US1NYWC0003\",\"WHITE PLAINS 3.1 NNW, NY US\",\"41.0639\",\"-73.7722\",\"71.0\",\"2016-12-06\",,\"0.00\",\"0.0\",,,,\n\"US1NYWC0003\",\"WHITE PLAINS 3.1 NNW, NY US\",\"41.0639\",\"-73.7722\",\"71.0\",\"2016-12-07\",,\"0.32\",,,,,\n\"US1NYWC0003\",\"WHITE PLAINS 3.1 NNW, NY US\",\"41.0639\",\"-73.7722\",\"71.0\",\"2016-12-08\",,\"0.00\",\"0.0\",,,,\n\"US1NYWC0003\",\"WHITE PLAINS 3.1 NNW, NY US\",\"41.0639\",\"-73.7722\",\"71.0\",\"2016-12-09\",,\"0.00\",\"0.0\",,,,\n.\n.\ndone\n"}]},"apps":[],"jobName":"paragraph_1507294464744_429431200","id":"20171006-125424_1155428025","dateCreated":"2017-10-06T12:54:24+0000","dateStarted":"2017-10-06T13:25:11+0000","dateFinished":"2017-10-06T13:25:29+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1192"},{"text":"%md\n## Reading the weather data and registering as a Spark SQL table\n\nThe next step is to use Spark to read our weather data CSV file that we uploaded to the Object Store.  Once we read the CSV into a Spark Data Frame, we will register the data frame as a Spark SQL temp table.\n\nYou can review the Spark SQL programming guide for a refresher about Data Frames and Temporary Tables: <a href=\"https://spark.apache.org/docs/2.1.0/sql-programming-guide.html\" target=\"_blank\">Spark SQL Programming Guide</a>\n\n","dateUpdated":"2017-10-06T13:27:26+0000","config":{"tableHide":false,"editorSetting":{"editOnDblClick":"true","language":"markdown"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Reading the weather data and registering as a Spark SQL table</h2>\n<p>The next step is to use Spark to read our weather data CSV file that we uploaded to the Object Store. Once we read the CSV into a Spark Data Frame, we will register the data frame as a Spark SQL temp table.</p>\n<p>You can review the Spark SQL programming guide for a refresher about Data Frames and Temporary Tables: <a href=\"https://spark.apache.org/docs/2.1.0/sql-programming-guide.html\" target=\"_blank\">Spark SQL Programming Guide</a></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1507291908123_-1232332639","id":"20170417-090240_1793194469","dateCreated":"2017-10-06T12:11:48+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1194","user":"anonymous","dateFinished":"2017-10-06T13:27:26+0000","dateStarted":"2017-10-06T13:27:26+0000"},{"title":"Spark Scala to read CSV and register as table (takes 1-3 minutes)","text":"%spark\n\n\nval Container = \"journeyC\"\nval Directory = \"weather\"\n\n//val df = sqlContext.read.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").load(\"swift://\"+Container+\".default/\"+Directory+\"/raw/201612-weather.csv\")\n//We will use the bdfs (alluxio) cached file system to access our object store data...\nval wdf = sqlContext.read.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").option(\"inferSchema\",\"true\").load(\"bdfs://localhost:19998/\"+Directory+\"/raw/201612-weather.csv\")\n\n// If you get this error message:\n// java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.\n// Then go to the Settings tab, then click on Notebook.  Then restart the Notebook.  This will restart your SparkContext\n\n\nprintln(\"Here is the schema detected from the CSV\")\nwdf.printSchema()\nprintln(\"..\")\n\nprintln(\"# of rows: %s\".format(\n  wdf.count() \n)) \nprintln(\"..\")\n\nwdf.registerTempTable(\"weather_temp\")\nprintln(\"done\")","dateUpdated":"2017-10-06T13:28:44+0000","config":{"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"title":true,"results":{},"graph":{"mode":"table","height":247,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{"container":"dcb-bdcs-apr12","CONTAINER":"citibike","FILENAME":"201612-citibike-tripdata"},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nContainer: String = journeyC\n\nDirectory: String = weather\n\nwdf: org.apache.spark.sql.DataFrame = [STATION: string, NAME: string ... 11 more fields]\nHere is the schema detected from the CSV\nroot\n |-- STATION: string (nullable = true)\n |-- NAME: string (nullable = true)\n |-- LATITUDE: double (nullable = true)\n |-- LONGITUDE: double (nullable = true)\n |-- ELEVATION: double (nullable = true)\n |-- DATE: timestamp (nullable = true)\n |-- AWND: double (nullable = true)\n |-- PRCP: double (nullable = true)\n |-- SNOW: double (nullable = true)\n |-- SNWD: integer (nullable = true)\n |-- TAVG: integer (nullable = true)\n |-- TMAX: integer (nullable = true)\n |-- TMIN: integer (nullable = true)\n\n..\n# of rows: 2576\n..\n\nwarning: there was one deprecation warning; re-run with -deprecation for details\ndone\n"}]},"apps":[],"jobName":"paragraph_1507291908124_-1234256384","id":"20170414-134031_1271833288","dateCreated":"2017-10-06T12:11:48+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1196","user":"anonymous","dateFinished":"2017-10-06T13:28:56+0000","dateStarted":"2017-10-06T13:28:44+0000"},{"text":"%sql\nselect * from weather_temp\nwhere NAME like '%CENTRAL%'","user":"anonymous","dateUpdated":"2017-10-06T13:30:34+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"text","editOnDblClick":false},"editorMode":"ace/mode/text","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1507296560218_-8610094","id":"20171006-132920_1541770419","dateCreated":"2017-10-06T13:29:20+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3138","dateFinished":"2017-10-06T13:30:01+0000","dateStarted":"2017-10-06T13:30:01+0000","title":"SQL to experiment with our Weather data","results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"STATION\tNAME\tLATITUDE\tLONGITUDE\tELEVATION\tDATE\tAWND\tPRCP\tSNOW\tSNWD\tTAVG\tTMAX\tTMIN\nUSW00094728\tNY CITY CENTRAL PARK, NY US\t40.77898\t-73.96925\t42.7\t2016-12-01 00:00:00.0\t7.61\t0.07\t0.0\t0\tnull\t54\t42\nUSW00094728\tNY CITY CENTRAL PARK, NY US\t40.77898\t-73.96925\t42.7\t2016-12-02 00:00:00.0\t8.72\t0.0\t0.0\t0\tnull\t51\t40\nUSW00094728\tNY CITY CENTRAL PARK, NY US\t40.77898\t-73.96925\t42.7\t2016-12-03 00:00:00.0\t8.72\t0.0\t0.0\t0\tnull\t47\t41\nUSW00094728\tNY CITY CENTRAL PARK, NY US\t40.77898\t-73.96925\t42.7\t2016-12-04 00:00:00.0\t4.92\t0.0\t0.0\t0\tnull\t47\t39\nUSW00094728\tNY CITY CENTRAL PARK, NY US\t40.77898\t-73.96925\t42.7\t2016-12-05 00:00:00.0\t5.59\t0.19\t0.0\t0\tnull\t49\t38\nUSW00094728\tNY CITY CENTRAL PARK, NY US\t40.77898\t-73.96925\t42.7\t2016-12-06 00:00:00.0\t5.37\t0.35\t0.0\t0\tnull\t46\t37\nUSW00094728\tNY CITY CENTRAL PARK, NY US\t40.77898\t-73.96925\t42.7\t2016-12-07 00:00:00.0\t3.8\t0.09\t0.0\t0\tnull\t46\t40\nUSW00094728\tNY CITY CENTRAL PARK, NY US\t40.77898\t-73.96925\t42.7\t2016-12-08 00:00:00.0\tnull\t0.0\t0.0\t0\tnull\t45\t35\nUSW00094728\tNY CITY CENTRAL PARK, NY US\t40.77898\t-73.96925\t42.7\t2016-12-09 00:00:00.0\tnull\t0.0\t0.0\t0\tnull\t39\t29\nUSW00094728\tNY CITY CENTRAL PARK, NY US\t40.77898\t-73.96925\t42.7\t2016-12-10 00:00:00.0\t6.04\t0.0\t0.0\t0\tnull\t35\t28\nUSW00094728\tNY CITY CENTRAL PARK, NY US\t40.77898\t-73.96925\t42.7\t2016-12-11 00:00:00.0\t4.03\t0.03\t0.4\t0\tnull\t35\t28\nUSW00094728\tNY CITY CENTRAL PARK, NY US\t40.77898\t-73.96925\t42.7\t2016-12-12 00:00:00.0\t6.26\t0.5\t0.0\t0\tnull\t46\t34\nUSW00094728\tNY CITY CENTRAL PARK, NY US\t40.77898\t-73.96925\t42.7\t2016-12-13 00:00:00.0\t4.03\t0.0\t0.0\t0\tnull\t43\t35\nUSW00094728\tNY CITY CENTRAL PARK, NY US\t40.77898\t-73.96925\t42.7\t2016-12-14 00:00:00.0\t5.59\t0.0\t0.0\t0\tnull\t42\t34\nUSW00094728\tNY CITY CENTRAL PARK, NY US\t40.77898\t-73.96925\t42.7\t2016-12-15 00:00:00.0\t10.96\t0.0\t0.0\t0\tnull\t34\t19\nUSW00094728\tNY CITY CENTRAL PARK, NY US\t40.77898\t-73.96925\t42.7\t2016-12-16 00:00:00.0\t6.04\t0.0\t0.0\t0\tnull\t27\t17\nUSW00094728\tNY CITY CENTRAL PARK, NY US\t40.77898\t-73.96925\t42.7\t2016-12-17 00:00:00.0\t4.25\t0.73\t2.8\t2\tnull\t39\t24\nUSW00094728\tNY CITY CENTRAL PARK, NY US\t40.77898\t-73.96925\t42.7\t2016-12-18 00:00:00.0\t7.38\t0.04\t0.0\t1\tnull\t58\t31\nUSW00094728\tNY CITY CENTRAL PARK, NY US\t40.77898\t-73.96925\t42.7\t2016-12-19 00:00:00.0\t6.71\t0.0\t0.0\t0\tnull\t31\t23\nUSW00094728\tNY CITY CENTRAL PARK, NY US\t40.77898\t-73.96925\t42.7\t2016-12-20 00:00:00.0\t3.13\t0.0\t0.0\t0\tnull\t33\t20\nUSW00094728\tNY CITY CENTRAL PARK, NY US\t40.77898\t-73.96925\t42.7\t2016-12-21 00:00:00.0\t2.91\t0.0\t0.0\t0\tnull\t40\t30\nUSW00094728\tNY CITY CENTRAL PARK, NY US\t40.77898\t-73.96925\t42.7\t2016-12-22 00:00:00.0\t6.26\t0.0\t0.0\t0\tnull\t49\t37\nUSW00094728\tNY CITY CENTRAL PARK, NY US\t40.77898\t-73.96925\t42.7\t2016-12-23 00:00:00.0\t6.49\t0.0\t0.0\t0\tnull\t47\t38\nUSW00094728\tNY CITY CENTRAL PARK, NY US\t40.77898\t-73.96925\t42.7\t2016-12-24 00:00:00.0\t4.92\t0.47\t0.0\t0\tnull\t47\t38\nUSW00094728\tNY CITY CENTRAL PARK, NY US\t40.77898\t-73.96925\t42.7\t2016-12-25 00:00:00.0\t6.26\t0.0\t0.0\t0\tnull\t50\t36\nUSW00094728\tNY CITY CENTRAL PARK, NY US\t40.77898\t-73.96925\t42.7\t2016-12-26 00:00:00.0\t6.49\t0.02\t0.0\t0\tnull\t50\t33\nUSW00094728\tNY CITY CENTRAL PARK, NY US\t40.77898\t-73.96925\t42.7\t2016-12-27 00:00:00.0\t7.16\t0.0\t0.0\t0\tnull\t60\t40\nUSW00094728\tNY CITY CENTRAL PARK, NY US\t40.77898\t-73.96925\t42.7\t2016-12-28 00:00:00.0\t5.14\t0.0\t0.0\t0\tnull\t40\t34\nUSW00094728\tNY CITY CENTRAL PARK, NY US\t40.77898\t-73.96925\t42.7\t2016-12-29 00:00:00.0\t5.37\t0.39\t0.0\t0\tnull\t46\t33\nUSW00094728\tNY CITY CENTRAL PARK, NY US\t40.77898\t-73.96925\t42.7\t2016-12-30 00:00:00.0\t9.4\t0.01\t0.0\t0\tnull\t40\t33\nUSW00094728\tNY CITY CENTRAL PARK, NY US\t40.77898\t-73.96925\t42.7\t2016-12-31 00:00:00.0\t6.93\t0.0\t0.0\t0\tnull\t44\t31\n"}]}},{"text":"%sql\nselect cast(date as date) day_of_month, tmax, tmin, prcp*20 prcp_scaled\nfrom weather_temp\nwhere station='USW00094728'\norder by day_of_month","user":"anonymous","dateUpdated":"2017-10-06T13:38:02+0000","config":{"colWidth":12,"enabled":true,"results":{"0":{"graph":{"mode":"lineChart","height":300,"optionOpen":false,"setting":{"lineChart":{"lineWithFocus":false}},"commonSetting":{},"keys":[{"name":"day_of_month","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"tmax","index":1,"aggr":"sum"},{"name":"tmin","index":2,"aggr":"sum"},{"name":"prcp_scaled","index":3,"aggr":"sum"}]},"helium":{}}},"editorSetting":{"language":"sql"},"editorMode":"ace/mode/sql","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1507296637983_-2116741263","id":"20171006-133037_1442897346","dateCreated":"2017-10-06T13:30:37+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3358","dateFinished":"2017-10-06T13:38:02+0000","dateStarted":"2017-10-06T13:38:02+0000","title":"More SQL to experiment with our Weather data","results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"day_of_month\ttmax\ttmin\tprcp_scaled\n2016-12-01\t54\t42\t1.4000000000000001\n2016-12-02\t51\t40\t0.0\n2016-12-03\t47\t41\t0.0\n2016-12-04\t47\t39\t0.0\n2016-12-05\t49\t38\t3.8\n2016-12-06\t46\t37\t7.0\n2016-12-07\t46\t40\t1.7999999999999998\n2016-12-08\t45\t35\t0.0\n2016-12-09\t39\t29\t0.0\n2016-12-10\t35\t28\t0.0\n2016-12-11\t35\t28\t0.6\n2016-12-12\t46\t34\t10.0\n2016-12-13\t43\t35\t0.0\n2016-12-14\t42\t34\t0.0\n2016-12-15\t34\t19\t0.0\n2016-12-16\t27\t17\t0.0\n2016-12-17\t39\t24\t14.6\n2016-12-18\t58\t31\t0.8\n2016-12-19\t31\t23\t0.0\n2016-12-20\t33\t20\t0.0\n2016-12-21\t40\t30\t0.0\n2016-12-22\t49\t37\t0.0\n2016-12-23\t47\t38\t0.0\n2016-12-24\t47\t38\t9.399999999999999\n2016-12-25\t50\t36\t0.0\n2016-12-26\t50\t33\t0.4\n2016-12-27\t60\t40\t0.0\n2016-12-28\t40\t34\t0.0\n2016-12-29\t46\t33\t7.800000000000001\n2016-12-30\t40\t33\t0.2\n2016-12-31\t44\t31\t0.0\n"}]}},{"text":"%md\n# Creating a calendar dataset\n\nIn addition to weather, let's add some calendar data such as holidays and attributes about workdays and weekends.  Since there are not many holidays, it seems like overkill to create a new file and upload it just to keep track.  Instead, we'll programatically create a new holiday dataset in the next paragraph.","user":"anonymous","dateUpdated":"2017-10-06T13:41:35+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":"true"},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1507297105454_-489580157","id":"20171006-133825_216597577","dateCreated":"2017-10-06T13:38:25+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4714","dateFinished":"2017-10-06T13:41:35+0000","dateStarted":"2017-10-06T13:41:35+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Creating a calendar dataset</h1>\n<p>In addition to weather, let&rsquo;s add some calendar data such as holidays and attributes about workdays and weekends. Since there are not many holidays, it seems like overkill to create a new file and upload it just to keep track. Instead, we&rsquo;ll programatically create a new holiday dataset in the next paragraph.</p>\n</div>"}]}},{"title":"Create a temp table for Holidays","text":"%spark\n\ncase class Holiday(hdate: String)\n// Encoders are created for case classes\nval hdf = Seq(Holiday(\"2016-12-24\"), Holiday(\"2016-12-25\"), Holiday(\"2016-12-26\"), Holiday(\"2016-12-31\")).toDS()\nhdf.show()\n\nprintln(\"..\")\n\nprintln(\"# of rows: %s\".format(\n  hdf.count() \n)) \nprintln(\"..\")\n\nhdf.registerTempTable(\"holidays_temp\")\nprintln(\"done\")\n","dateUpdated":"2017-10-06T13:53:38+0000","config":{"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1507291908125_-1234641133","id":"20170928-205441_1475760890","dateCreated":"2017-10-06T12:11:48+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1198","user":"anonymous","dateFinished":"2017-10-06T13:53:39+0000","dateStarted":"2017-10-06T13:53:38+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\ndefined class Holiday\n\nhdf: org.apache.spark.sql.Dataset[Holiday] = [hdate: string]\n+----------+\n|     hdate|\n+----------+\n|2016-12-24|\n|2016-12-25|\n|2016-12-26|\n|2016-12-31|\n+----------+\n\n..\n# of rows: 4\n..\n\nwarning: there was one deprecation warning; re-run with -deprecation for details\ndone\n"}]}},{"text":"%sql\nselect * from holidays_temp","user":"anonymous","dateUpdated":"2017-10-06T13:54:23+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"text","editOnDblClick":false},"editorMode":"ace/mode/text","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1507298026408_297193594","id":"20171006-135346_1679843670","dateCreated":"2017-10-06T13:53:46+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:5047","dateFinished":"2017-10-06T13:54:23+0000","dateStarted":"2017-10-06T13:54:23+0000","title":"SQL to experiment with our holidays dataset","results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"hdate\n2016-12-24\n2016-12-25\n2016-12-26\n2016-12-31\n"}]}},{"text":"%sql\nselect cast(date as date) day_of_month, tmax, tmin, h.hdate , \n   IF(isnull(h.hdate), 'N', 'Holiday') holiday,\n   IF(!isnull(h.hdate) & dayofweek(date)=3, 'N', 'Workday') workday\nfrom weather_temp w LEFT OUTER JOIN holidays_temp h\nON (w.date = h.hdate)\nwhere station='USW00094728'\norder by day_of_month","user":"anonymous","dateUpdated":"2017-10-06T16:54:44+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1507298067299_537539063","id":"20171006-135427_1646189665","dateCreated":"2017-10-06T13:54:27+0000","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:5194","dateFinished":"2017-10-06T16:54:45+0000","dateStarted":"2017-10-06T16:54:45+0000","title":"SQL to experiment with combining holidays and weather","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Undefined function: 'dayofweek'. This function is neither a registered temporary function nor a permanent function registered in the database 'default'.; line 3 pos 25\nset zeppelin.spark.sql.stacktrace = true to see full stacktrace"}]}},{"title":"Create a permanent table of bike trips joined with weather","text":"%sql\ncreate table bike_trips_weather_parquet\nstored as parquet\nselect   `Trip Duration` TRIPDURATION,\n`Start Time` STARTTIME,\n`Stop Time` STOPTIME,\n`Start Station ID` STARTSTATIONID,\n`Start Station Name` STARTSTATIONNAME,\n`Start Station Latitude` STARTSTATIONLATITUDE,\n`Start Station Longitude` STARTSTATIONLONGITUDE,\n`End Station ID` ENDSTATIONID,\n`End Station Name` ENDSTATIONNAME,\n`End Station Latitude` ENDSTATIONLATITUDE,\n`End Station Longitude` ENDSTATIONLONGITUDE,\n`Bike ID` BIKEID,\n`User Type` USERTYPE,\n`Birth Year` BIRTHYEAR,\n`Gender` GENDER, w.AWND AVERAGEWIND, w.PRCP PRECIPITATION, w.SNOW SNOW, w.SNWD SNOW_ON_GROUND, w.TMAX MAXTEMPERATURE, w.TMIN MINTEMPERATURE from weather_temp w,\nbike_trips_temp t\nwhere to_date(w.date) = to_date(t.`Start Time`)\n","dateUpdated":"2017-10-06T12:11:48+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/sql","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"`default`.`bike_trips_weather_parquet` already exists.;\nset zeppelin.spark.sql.stacktrace = true to see full stacktrace"}]},"apps":[],"jobName":"paragraph_1507291908126_-1233486886","id":"20170928-202705_1728257996","dateCreated":"2017-10-06T12:11:48+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1199"},{"text":"%md\n# Querying the bike trip information\n\nNow we can show some examples of querying our bike_trips table.  You will need to have first run the above paragraph to ensure that the temporary table bike_trips_temp is registered in your current Spark Session.","dateUpdated":"2017-10-06T12:11:48+0000","config":{"tableHide":false,"editorSetting":{"editOnDblClick":"true","language":"markdown"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Querying the bike trip information</h1>\n<p>Now we can show some examples of querying our bike_trips table. You will need to have first run the above paragraph to ensure that the temporary table bike_trips_temp is registered in your current Spark Session.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1507291908126_-1233486886","id":"20170417-093337_291620887","dateCreated":"2017-10-06T12:11:48+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1200"},{"title":"Trips by Gender","text":"%sql\nselect \n case when a.gender=1 then 'Male' when a.gender=2 then 'Female' else 'unknown' end gender ,\n        a.trip_count \nfrom (select gender, count(*) trip_count from bike_trips_temp\ngroup by gender) a","dateUpdated":"2017-10-06T12:11:48+0000","config":{"editorSetting":{"language":"sql"},"colWidth":6,"editorMode":"ace/mode/sql","title":true,"results":[{"graph":{"mode":"pieChart","height":294,"optionOpen":false,"keys":[{"name":"gender","index":0,"aggr":"sum"}],"values":[{"name":"trip_count","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"gender","index":0,"aggr":"sum"}}}}],"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1507291908127_-1233871635","id":"20170417-095126_1698083225","dateCreated":"2017-10-06T12:11:48+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1201"},{"title":"Trips by Day of Month","text":"%sql\nselect dayofmonth, count(*)\nfrom (select date_format(`Start Time`,\"H\") hour,\n date_format(`Start Time`,\"E\") dayofweek,\n date_format(`Start Time`,\"d\") dayofmonth\nfrom bike_trips_temp) bike_times\ngroup by dayofmonth","dateUpdated":"2017-10-06T12:11:48+0000","config":{"editorSetting":{"language":"sql"},"colWidth":6,"editorMode":"ace/mode/sql","title":true,"results":[{"graph":{"mode":"lineChart","height":314,"optionOpen":false,"keys":[{"name":"dayofmonth","index":0,"aggr":"sum"}],"values":[{"name":"count(1)","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"dayofmonth","index":0,"aggr":"sum"},"yAxis":{"name":"_c1","index":1,"aggr":"sum"}},"forceY":true,"setting":{"lineChart":{}},"commonSetting":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1507291908127_-1233871635","id":"20170417-095623_1767722062","dateCreated":"2017-10-06T12:11:48+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1202"},{"title":"Trips by Day of Week and Gender","text":"%sql\nselect dayofweek, count(*)\nfrom (select date_format(`Start Time`,\"H\") hour,\n date_format(`Start Time`,\"E\") dayofweek,\n date_format(`Start Time`,\"d\") dayofmonth,\n case when gender=1 then 'Male' when gender=2 then 'Female' else 'unknown' end gender \nfrom bike_trips_temp) bike_times\nwhere (gender=\"${gender=Male,Male|Female|unknown}\" )\ngroup by dayofweek","dateUpdated":"2017-10-06T12:11:48+0000","config":{"editorSetting":{"language":"sql"},"colWidth":6,"editorMode":"ace/mode/sql","title":true,"results":[{"graph":{"mode":"pieChart","height":300,"optionOpen":false,"keys":[{"name":"dayofweek","index":0,"aggr":"sum"}],"values":[{"name":"count(1)","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"dayofweek","index":0,"aggr":"sum"}},"setting":{"pieChart":{}},"commonSetting":{}}}],"enabled":true},"settings":{"params":{"gender":"Male"},"forms":{"gender":{"name":"gender","defaultValue":"Male","options":[{"value":"Male","$$hashKey":"object:1822"},{"value":"Female","$$hashKey":"object:1823"},{"value":"unknown","$$hashKey":"object:1824"}],"hidden":false,"$$hashKey":"object:1815"}}},"apps":[],"jobName":"paragraph_1507291908128_-1248107344","id":"20170417-101619_429877425","dateCreated":"2017-10-06T12:11:48+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1203"},{"title":"Bike Trips by Hour by day of week","text":"%sql\nselect dayofweek, hour, count(*)\nfrom (select date_format(`Start Time`,\"H\") hour,\n date_format(`Start Time`,\"E\") dayofweek,\n date_format(`Start Time`,\"d\") dayofmonth,\n case when gender=1 then 'Male' when gender=2 then 'Female' else 'unknown' end gender \nfrom bike_trips_temp) bike_times\nwhere (gender=\"${gender=Male,Male|Female|unknown}\" )\ngroup by dayofweek, hour","dateUpdated":"2017-10-06T12:11:48+0000","config":{"editorSetting":{"language":"sql"},"colWidth":6,"editorMode":"ace/mode/sql","title":true,"results":[{"graph":{"mode":"lineChart","height":300,"optionOpen":false,"keys":[{"name":"hour","index":1,"aggr":"sum"}],"values":[{"name":"count(1)","index":2,"aggr":"sum"}],"groups":[{"name":"dayofweek","index":0,"aggr":"sum"}],"scatter":{"xAxis":{"name":"dayofweek","index":0,"aggr":"sum"},"yAxis":{"name":"hour","index":1,"aggr":"sum"}},"forceY":true,"lineWithFocus":false,"setting":{"lineChart":{}},"commonSetting":{}}}],"enabled":true},"settings":{"params":{"gender":"Male"},"forms":{"gender":{"name":"gender","defaultValue":"Male","options":[{"value":"Male","$$hashKey":"object:1832"},{"value":"Female","$$hashKey":"object:1833"},{"value":"unknown","$$hashKey":"object:1834"}],"hidden":false,"$$hashKey":"object:1825"}}},"apps":[],"jobName":"paragraph_1507291908128_-1248107344","id":"20170414-134451_506665191","dateCreated":"2017-10-06T12:11:48+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1204"},{"text":"%md\n# Next Steps\n\nSo far, we have downloaded Citi Bike data and stored it into the Object Store.  Then, we configured Spark to be able to work with CSV files.  Then, we read in the data and defined a Spark SQL temporary table with it.  Finally, we demonstrated a number of different queries.  Did you notice any patterns?  For instance, that men use Citi Bikes more than women?  That on workdays (Mon-Fri) there is a peak around 8am and 5pm, but that peak does not exist on Saturday and Sunday?   \n\nHere are some suggested next steps:\n\n+ Run the Demonstration Presidental Speeches with Spark and Spark SQL\n+ Explore the Tutorial Spark and Maps in Zeppelin\n+ Upload some of your own data to the Object Store and experiment with Spark and Spark SQL\n","dateUpdated":"2017-10-06T12:11:48+0000","config":{"tableHide":false,"editorSetting":{"editOnDblClick":"true","language":"markdown"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Next Steps</h1>\n<p>So far, we have downloaded Citi Bike data and stored it into the Object Store. Then, we configured Spark to be able to work with CSV files. Then, we read in the data and defined a Spark SQL temporary table with it. Finally, we demonstrated a number of different queries. Did you notice any patterns? For instance, that men use Citi Bikes more than women? That on workdays (Mon-Fri) there is a peak around 8am and 5pm, but that peak does not exist on Saturday and Sunday? </p>\n<p>Here are some suggested next steps:</p>\n<ul>\n  <li>Run the Demonstration Presidental Speeches with Spark and Spark SQL</li>\n  <li>Explore the Tutorial Spark and Maps in Zeppelin</li>\n  <li>Upload some of your own data to the Object Store and experiment with Spark and Spark SQL</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1507291908129_-1248492093","id":"20170417-103925_248941849","dateCreated":"2017-10-06T12:11:48+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1205"},{"text":"%md\n# Extra Credit - Saving our temporary Spark SQL table as a permanent Hive table\n\nThe next few paragraphs show you how you can save a copy of the Spark SQL temporary table as a new permament Hive table.  This might be useful if you want to use BI tools, like Oracle Data Visualization Desktop, to query the permanent table.\n\nThe only trick is that Hive doesn't like spaces in column names, so we rename our columns in our Create Table as Select statement below.","dateUpdated":"2017-10-06T12:11:48+0000","config":{"tableHide":false,"editorSetting":{"editOnDblClick":"true","language":"markdown"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Extra Credit - Saving our temporary Spark SQL table as a permanent Hive table</h1>\n<p>The next few paragraphs show you how you can save a copy of the Spark SQL temporary table as a new permament Hive table. This might be useful if you want to use BI tools, like Oracle Data Visualization Desktop, to query the permanent table.</p>\n<p>The only trick is that Hive doesn&rsquo;t like spaces in column names, so we rename our columns in our Create Table as Select statement below.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1507291908129_-1248492093","id":"20170505-092652_1652882871","dateCreated":"2017-10-06T12:11:48+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1206"},{"title":"Query to list our hive tables BEFORE","text":"%sql\nshow tables","dateUpdated":"2017-10-06T12:11:48+0000","config":{"editorSetting":{"language":"sql"},"colWidth":12,"editorMode":"ace/mode/sql","title":true,"results":[{"graph":{"mode":"table","height":174,"optionOpen":false,"keys":[{"name":"tableName","index":0,"aggr":"sum"}],"values":[{"name":"isTemporary","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"tableName","index":0,"aggr":"sum"},"yAxis":{"name":"isTemporary","index":1,"aggr":"sum"}}}}],"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1507291908132_-1249646340","id":"20170505-092452_1351056533","dateCreated":"2017-10-06T12:11:48+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1207"},{"title":"HiveQL to drop the table (in case you already ran the next step)","text":"%sql\ndrop table bike_trips_parquet","dateUpdated":"2017-10-06T12:11:48+0000","config":{"editorSetting":{"language":"sql"},"colWidth":12,"editorMode":"ace/mode/sql","title":true,"results":[],"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1507291908133_-1250031089","id":"20170612-094821_740135087","dateCreated":"2017-10-06T12:11:48+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1208"},{"title":"HiveQL to create a permanent Hive table from our SparkSQL temporary table (this will have no output)","text":"%sql\ncreate table bike_trips_parquet\nstored as parquet\nas select `Trip Duration` TRIPDURATION,\n`Start Time` STARTTIME,\n`Stop Time` STOPTIME,\n`Start Station ID` STARTSTATIONID,\n`Start Station Name` STARTSTATIONNAME,\n`Start Station Latitude` STARTSTATIONLATITUDE,\n`Start Station Longitude` STARTSTATIONLONGITUDE,\n`End Station ID` ENDSTATIONID,\n`End Station Name` ENDSTATIONNAME,\n`End Station Latitude` ENDSTATIONLATITUDE,\n`End Station Longitude` ENDSTATIONLONGITUDE,\n`Bike ID` BIKEID,\n`User Type` USERTYPE,\n`Birth Year` BIRTHYEAR,\n`Gender` GENDER\n from bike_trips_temp","dateUpdated":"2017-10-06T12:11:48+0000","config":{"editorSetting":{"language":"sql"},"colWidth":12,"editorMode":"ace/mode/sql","title":true,"results":[],"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1507291908133_-1250031089","id":"20170414-151953_1584996855","dateCreated":"2017-10-06T12:11:48+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1209"},{"title":"Query to show our new permanent table in action","text":"%sql\nselect * from bike_trips_parquet limit 5","dateUpdated":"2017-10-06T12:11:48+0000","config":{"editorSetting":{"language":"sql"},"colWidth":12,"editorMode":"ace/mode/sql","title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[{"name":"tripduration","index":0,"aggr":"sum"}],"values":[{"name":"starttime","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"tripduration","index":0,"aggr":"sum"},"yAxis":{"name":"starttime","index":1,"aggr":"sum"}}}}],"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1507291908137_-1251570084","id":"20170503-195617_839333002","dateCreated":"2017-10-06T12:11:48+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1210"},{"title":"Query to list our Hive tables AFTER","text":"%sql\nshow tables","dateUpdated":"2017-10-06T12:11:48+0000","config":{"editorSetting":{"language":"sql"},"colWidth":12,"editorMode":"ace/mode/sql","title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[{"name":"tableName","index":0,"aggr":"sum"}],"values":[{"name":"isTemporary","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"tableName","index":0,"aggr":"sum"},"yAxis":{"name":"isTemporary","index":1,"aggr":"sum"}}}}],"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1507291908138_-1250415838","id":"20170503-195744_526374432","dateCreated":"2017-10-06T12:11:48+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1211"},{"text":"%md\n### Change Log\nSeptember 7, 2017 - Confirmed it works with 17.3.5-20.  Switched filepath to bdfs\nAugust 23, 2017 - Minor tweaks\nAugust 13, 2017 - Confirmed it works with 17.3.3-20.\nAugust 11, 2017 - Journey v2.  Confirmed it worked with Spark2.1\nJuly 28, 2017 - Confirmed it works with 17.3.1-20.","dateUpdated":"2017-10-06T12:11:48+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":"true"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Change Log</h3>\n<p>September 7, 2017 - Confirmed it works with 17.3.5-20. Switched filepath to bdfs<br/>August 23, 2017 - Minor tweaks<br/>August 13, 2017 - Confirmed it works with 17.3.3-20.<br/>August 11, 2017 - Journey v2. Confirmed it worked with Spark2.1<br/>July 28, 2017 - Confirmed it works with 17.3.1-20.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1507291908138_-1250415838","id":"20170614-163657_1564876178","dateCreated":"2017-10-06T12:11:48+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1212"},{"text":"%md\n","dateUpdated":"2017-10-06T12:11:48+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","results":{},"enabled":true,"editorSetting":{"language":"markdown","editOnDblClick":"true"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1507291908139_-1250800586","id":"20170728-131606_1414555962","dateCreated":"2017-10-06T12:11:48+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1213"}],"name":"Tutorial 4-2 Adding more datasets","id":"2CW26NXWC","angularObjects":{"2CTS8VR5A:shared_process":[],"2CVCR69ZH:shared_process":[],"2CVHY6238:shared_process":[],"2CWY45EYM:shared_process":[],"2CW9FYFKK:shared_process":[],"2CWCB1P91:shared_process":[],"2C4U48MY3_spark2:shared_process":[],"2CUKFQTQZ:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}