{"paragraphs":[{"text":"%md\n# xtra tutorial: Working with Oracle Data Visualization Desktop and Spark\n\nThis tutorial was built for BDCS-CE version 17.3.5-20 as part of the New Data Lake User Journey: <a href=\"https://github.com/oracle/learning-library/tree/master/workshops/journey2-new-data-lake\" target=\"_blank\">here</a>.  Questions and feedback about the tutorial: <david.bayard@oracle.com>\n\n\n    Note: This tutorial assumes you have tables defined in the Hive metastore which you should have if you ran the earlier tutorials.\n\nOracle Data Visualization Desktop ( <a href=\"https://docs.oracle.com/middleware/bidv1221/desktop/index.html\" target=\"_blank\">here</a> ) is a lightweight, single-file download tool to easily analyze data.  Data Visualization Desktop can connect to a variety of data sources.  In this tutorial, we will show you how you can use it to securely connect to BDCS-CE.  We will connect via DV Desktop's support for Spark.  \n\nPlease follow the instructions in the xtra Connecting DV Desktop and Hive for the DVD download and install instructions.\n","dateUpdated":"2017-09-11T20:32:25+0000","config":{"tableHide":false,"editorSetting":{"editOnDblClick":"true","language":"markdown"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>xtra tutorial: Working with Oracle Data Visualization Desktop and Spark</h1>\n<p>This tutorial was built for BDCS-CE version 17.3.5-20 as part of the New Data Lake User Journey: <a href=\"https://github.com/oracle/learning-library/tree/master/workshops/journey2-new-data-lake\" target=\"_blank\">here</a>. Questions and feedback about the tutorial: <a href=\"mailto:&#x64;&#97;v&#x69;&#x64;&#x2e;&#98;ay&#x61;r&#100;&#64;or&#97;&#x63;&#x6c;&#x65;&#x2e;&#99;&#111;&#x6d;\">&#x64;&#97;v&#x69;&#x64;&#x2e;&#98;ay&#x61;r&#100;&#64;or&#97;&#x63;&#x6c;&#x65;&#x2e;&#99;&#111;&#x6d;</a></p>\n<pre><code>Note: This tutorial assumes you have tables defined in the Hive metastore which you should have if you ran the earlier tutorials.\n</code></pre>\n<p>Oracle Data Visualization Desktop ( <a href=\"https://docs.oracle.com/middleware/bidv1221/desktop/index.html\" target=\"_blank\">here</a> ) is a lightweight, single-file download tool to easily analyze data. Data Visualization Desktop can connect to a variety of data sources. In this tutorial, we will show you how you can use it to securely connect to BDCS-CE. We will connect via DV Desktop&rsquo;s support for Spark. </p>\n<p>Please follow the instructions in the xtra Connecting DV Desktop and Hive for the DVD download and install instructions.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1504646601869_1886148541","id":"20170504-171842_974565851","dateCreated":"2017-09-05T21:23:21+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1317","user":"anonymous","dateFinished":"2017-09-11T20:32:25+0000","dateStarted":"2017-09-11T20:32:25+0000"},{"text":"%md\n# Configuring the Spark Thrift Server process to use binary transport\n\nIn order to connect to Spark from DVD, we need to configure BDCS-CE's Spark Thrift Server to use the binary transport protocol.  By default, BDCS-CE's spark thrift server is configured to use the http transport protocol.  These changes are done using the Ambari web console.\n\nHere are the steps:\n\n1.Follow the note \"xtra Connecting to Ambari\" to login to Ambari.\n2.Once connected to Ambari, click on \"Spark2\" on the left-hand list of services\n3.Then click on the \"Configs\" tab\n4.In the search box, type \"server2\"\n5.In the Advanced spark2-hive-site-override section, change the \"hive.server2.transport.mode\" to binary.\n6.In the Custom spark2-hive-site-override section, remove the property \"hive.server2.thrift.bind.host\" (by clicking on the red - symbol)\n7.Click save\n8.In the notes field, enter \"transport mode\"\n9.Click save again\n10.If you see a \"Configurations\" pop-up, click \"Proceed Anyway\"\n11.Click OK to acknowledge that changes were made successfully\n12.Then click Restart, then Restart All Affected\n13.Then click Confirm Restart All\n\n![AmbariSparkBinary](https://raw.githubusercontent.com/oracle/learning-library/master/workshops/journey2-new-data-lake/images/300/AmbariSparkBinary.gif)\n\n\n","user":"anonymous","dateUpdated":"2017-09-11T21:16:43+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":"true"},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1505162114449_-1401130739","id":"20170911-203514_1066756941","dateCreated":"2017-09-11T20:35:14+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1611","dateFinished":"2017-09-11T21:16:43+0000","dateStarted":"2017-09-11T21:16:43+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Configuring the Spark Thrift Server process to use binary transport</h1>\n<p>In order to connect to Spark from DVD, we need to configure BDCS-CE&rsquo;s Spark Thrift Server to use the binary transport protocol. By default, BDCS-CE&rsquo;s spark thrift server is configured to use the http transport protocol. These changes are done using the Ambari web console.</p>\n<p>Here are the steps:</p>\n<p>1.Follow the note &ldquo;xtra Connecting to Ambari&rdquo; to login to Ambari.<br/>2.Once connected to Ambari, click on &ldquo;Spark2&rdquo; on the left-hand list of services<br/>3.Then click on the &ldquo;Configs&rdquo; tab<br/>4.In the search box, type &ldquo;server2&rdquo;<br/>5.In the Advanced spark2-hive-site-override section, change the &ldquo;hive.server2.transport.mode&rdquo; to binary.<br/>6.In the Custom spark2-hive-site-override section, remove the property &ldquo;hive.server2.thrift.bind.host&rdquo; (by clicking on the red - symbol)<br/>7.Click save<br/>8.In the notes field, enter &ldquo;transport mode&rdquo;<br/>9.Click save again<br/>10.If you see a &ldquo;Configurations&rdquo; pop-up, click &ldquo;Proceed Anyway&rdquo;<br/>11.Click OK to acknowledge that changes were made successfully<br/>12.Then click Restart, then Restart All Affected<br/>13.Then click Confirm Restart All</p>\n<p><img src=\"https://raw.githubusercontent.com/oracle/learning-library/master/workshops/journey2-new-data-lake/images/300/AmbariSparkBinary.gif\" alt=\"AmbariSparkBinary\" /></p>\n</div>"}]}},{"text":"%md\n# Connecting to the Spark Thrift Server port (10016)\n\nNow, you need to decide how you want to connect to the Spark Thrift Server port, which is port 10016.  You can either choose to use a SSH tunnel (which is very secure) or choose to open port 10016 to the outside world (which can be less secure).\n\n+ If you want to use a SSH tunnel, refer to the note \"xtra Connecting to Ambari\" which has an example of setting up a SSH tunnel (but you would use port 10016 instead of Ambari's 8080).\n+ If you want to open up port 10016, you will need to create a new access rule for port 10016.  Refer to the note \"xtra Connecting via SSH\" or \"OEHCS Tutorial 1\" for examples of working with network access rules.\n\n","user":"anonymous","dateUpdated":"2017-09-11T20:43:05+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":"true"},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1505162485921_1672546670","id":"20170911-204125_1313643018","dateCreated":"2017-09-11T20:41:25+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1694","dateFinished":"2017-09-11T20:43:05+0000","dateStarted":"2017-09-11T20:43:05+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Connecting to the Spark Thrift Server port (10016)</h1>\n<p>Now, you need to decide how you want to connect to the Spark Thrift Server port, which is port 10016. You can either choose to use a SSH tunnel (which is very secure) or choose to open port 10016 to the outside world (which can be less secure).</p>\n<ul>\n  <li>If you want to use a SSH tunnel, refer to the note &ldquo;xtra Connecting to Ambari&rdquo; which has an example of setting up a SSH tunnel (but you would use port 10016 instead of Ambari&rsquo;s 8080).</li>\n  <li>If you want to open up port 10016, you will need to create a new access rule for port 10016. Refer to the note &ldquo;xtra Connecting via SSH&rdquo; or &ldquo;OEHCS Tutorial 1&rdquo; for examples of working with network access rules.</li>\n</ul>\n</div>"}]}},{"text":"%md\n# Define a connection in DV Desktop for the Spark connection\n\n+ Open up DV Desktop\n+ Click on Data Sources\n+ Click on Connection (Under Create)\n+ Click on Spark\n+ Enter the Connection Name\n+ Enter the Host Name/IP for your BDCSCE instance.  The port should be the Thriftserver port for this instance. The default is 10016.\n+ Set the Username to the admin username you use to sign-in to your BDCSCE cluster/notebook (the default username is bdcsce_admin)\n+ Set the Password to the admin password you use to sign-in to your BDCSCE cluster\n\n![DVDconnection](https://raw.githubusercontent.com/oracle/learning-library/master/workshops/journey2-new-data-lake/images/300/DVDSparkconnection.bmp \"HODBC\")\n\n\n\n\n","dateUpdated":"2017-09-11T20:45:24+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":"true"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Define a connection in DV Desktop for the Spark connection</h1>\n<ul>\n  <li>Open up DV Desktop</li>\n  <li>Click on Data Sources</li>\n  <li>Click on Connection (Under Create)</li>\n  <li>Click on Spark</li>\n  <li>Enter the Connection Name</li>\n  <li>Enter the Host Name/IP for your BDCSCE instance. The port should be the Thriftserver port for this instance. The default is 10016.</li>\n  <li>Set the Username to the admin username you use to sign-in to your BDCSCE cluster/notebook (the default username is bdcsce_admin)</li>\n  <li>Set the Password to the admin password you use to sign-in to your BDCSCE cluster</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/oracle/learning-library/master/workshops/journey2-new-data-lake/images/300/DVDSparkconnection.bmp\" alt=\"DVDconnection\" title=\"HODBC\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1504646601870_1887302787","id":"20170728-174228_1743240708","dateCreated":"2017-09-05T21:23:21+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1318","user":"anonymous","dateFinished":"2017-09-11T20:45:24+0000","dateStarted":"2017-09-11T20:45:24+0000"},{"text":"%md\n# Create a DV Desktop Data Source for your connection\n\n+ Invoke the pop-up menu on your new Data Source and choose Create Data Source\n+ Navigate through the database, tables, and columns to choose the elements you want to add.\n+ Name the new data source and Add it\n\n![DVDdatasource](https://raw.githubusercontent.com/oracle/learning-library/master/workshops/journey2-new-data-lake/images/300/SparkDataSource.jpg \"HODBC\")\n","dateUpdated":"2017-09-11T20:45:33+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":"true"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Create a DV Desktop Data Source for your connection</h1>\n<ul>\n  <li>Invoke the pop-up menu on your new Data Source and choose Create Data Source</li>\n  <li>Navigate through the database, tables, and columns to choose the elements you want to add.</li>\n  <li>Name the new data source and Add it</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/oracle/learning-library/master/workshops/journey2-new-data-lake/images/300/SparkDataSource.jpg\" alt=\"DVDdatasource\" title=\"HODBC\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1504646601870_1887302787","id":"20170731-202416_1602004865","dateCreated":"2017-09-05T21:23:21+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1319","user":"anonymous","dateFinished":"2017-09-11T20:45:33+0000","dateStarted":"2017-09-11T20:45:33+0000"},{"text":"%md\n# Tip - DVD 3.0 with Spark 2.1 no databases appear\n\nThis may be https://issues.apache.org/jira/browse/SPARK-9686\n\nIn any case, we have noticed that no databases appear when querying Spark2.1 from DVD 3.0.\n\nThere is a workaround...\n\nWhen you create your data source, use the \"Enter SQL\" feature to define your sql.  It can be as simple as a \"select * from tablename\" or more complex.  \n\nHere is a video:\n![SparkCatalogWorkaround](https://raw.githubusercontent.com/oracle/learning-library/master/workshops/journey2-new-data-lake/images/300/SparkCatalogWorkaround.gif)\n\n\n\n","user":"anonymous","dateUpdated":"2017-09-11T21:17:52+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":"true"},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1505163923030_2068908080","id":"20170911-210523_432676084","dateCreated":"2017-09-11T21:05:23+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2311","dateFinished":"2017-09-11T21:17:52+0000","dateStarted":"2017-09-11T21:17:52+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Tip - DVD 3.0 with Spark 2.1 no databases appear</h1>\n<p>This may be <a href=\"https://issues.apache.org/jira/browse/SPARK-9686\">https://issues.apache.org/jira/browse/SPARK-9686</a></p>\n<p>In any case, we have noticed that no databases appear when querying Spark2.1 from DVD 3.0.</p>\n<p>There is a workaround&hellip;</p>\n<p>When you create your data source, use the &ldquo;Enter SQL&rdquo; feature to define your sql. It can be as simple as a &ldquo;select * from tablename&rdquo; or more complex. </p>\n<p>Here is a video:<br/><img src=\"https://raw.githubusercontent.com/oracle/learning-library/master/workshops/journey2-new-data-lake/images/300/SparkCatalogWorkaround.gif\" alt=\"SparkCatalogWorkaround\" /></p>\n</div>"}]}},{"text":"%md\n# Tip - Tracking Spark queries\n\nRun the following shell paragraph to peak at queries sent to the Spark thrift server.\n\n\n","user":"anonymous","dateUpdated":"2017-09-11T21:05:18+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":"true"},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1505162736617_-1816222251","id":"20170911-204536_1923836389","dateCreated":"2017-09-11T20:45:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1831","dateFinished":"2017-09-11T21:05:18+0000","dateStarted":"2017-09-11T21:05:18+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Tip - Tracking Spark queries</h1>\n<p>Run the following shell paragraph to peak at queries sent to the Spark thrift server.</p>\n</div>"}]}},{"text":"%sh\negrep $'Running|\\x0d|limit' /data/var/log/spark2-thrift/spark-hive-org.apache.spark.sql.hive.thriftserver.HiveThriftServer2-1-*-1.out\n","user":"anonymous","dateUpdated":"2017-09-11T21:14:45+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":"false"},"editorMode":"ace/mode/sh","editorHide":true,"tableHide":false,"title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1505162753735_-7871773","id":"20170911-204553_822044476","dateCreated":"2017-09-11T20:45:53+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1887","dateFinished":"2017-09-11T21:14:45+0000","dateStarted":"2017-09-11T21:14:45+0000","title":"Shell command to peak at queries sent to Spark Thrift Server","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"17/09/11 20:40:35 INFO SparkContext: Running Spark version 2.1.0.2.6.0.3-8\n17/09/11 20:44:08 INFO SparkExecuteStatementOperation: Running query 'use default' with b1c4559d-c7f3-4a0f-b100-835f406f8de4\n17/09/11 20:44:20 INFO SparkExecuteStatementOperation: Running query 'use default' with a9d8b6f7-daa3-4951-8c7b-866ccd8c2439\n17/09/11 20:46:15 INFO SparkExecuteStatementOperation: Running query 'use default' with 1a0c0882-564e-45bd-b1fd-0c858038635b\n17/09/11 20:46:15 INFO SparkExecuteStatementOperation: Running query 'select * from (select * from bike_trips bike_trips limit 50000) T0 WHERE 1=0' with 94ee827b-edbe-4f39-ad9b-ee430ecc6c79\n17/09/11 20:46:15 INFO SparkSqlParser: Parsing command: select * from (select * from bike_trips bike_trips limit 50000) T0 WHERE 1=0\n17/09/11 20:46:17 INFO SparkExecuteStatementOperation: Running query 'use default' with 6a3ef30e-1d85-4659-b92a-43e0dd40fb97\n17/09/11 20:46:17 INFO SparkExecuteStatementOperation: Running query 'select 0 as `c1`,\r\n     ROW_NUMBER() OVER ( ORDER BY D101.c1) as `c2`,\r\n     D101.c1 as `c3`,\r\n     D101.c2 as `c4`,\r\n     D101.c3 as `c5`,\r\n     D101.c4 as `c6`,\r\n     D101.c5 as `c7`,\r\n     D101.c6 as `c8`,\r\n     D101.c7 as `c9`,\r\n     D101.c8 as `c10`,\r\n     D101.c9 as `c11`,\r\n     D101.c10 as `c12`,\r\n     D101.c11 as `c13`,\r\n     D101.c12 as `c14`,\r\n     D101.c13 as `c15`,\r\n     D101.c14 as `c16`,\r\n     D101.c15 as `c17`\r\nfrom \r\n     (select T1000001.bikeid as `c1`,\r\n               T1000001.birthyear as `c2`,\r\n               T1000001.endstationid as `c3`,\r\n               T1000001.endstationlatitude as `c4`,\r\n               T1000001.endstationlongitude as `c5`,\r\n               T1000001.endstationname as `c6`,\r\n               T1000001.gender as `c7`,\r\n               T1000001.startstationid as `c8`,\r\n               T1000001.startstationlatitude as `c9`,\r\n               T1000001.startstationlongitude as `c10`,\r\n               T1000001.startstationname as `c11`,\r\n               T1000001.starttime as `c12`,\r\n               T1000001.stoptime as `c13`,\r\n               T1000001.tripduration as `c14`,\r\n               T1000001.usertype as `c15`\r\n          from \r\n               (select * from bike_trips bike_trips limit 50000) T1000001\r\n     ) D101 limit 21' with bc17ccd9-8b94-4916-b1dc-3e5a0d497e98\n17/09/11 20:46:17 INFO SparkSqlParser: Parsing command: select 0 as `c1`,\r\n     ROW_NUMBER() OVER ( ORDER BY D101.c1) as `c2`,\r\n     D101.c1 as `c3`,\r\n     D101.c2 as `c4`,\r\n     D101.c3 as `c5`,\r\n     D101.c4 as `c6`,\r\n     D101.c5 as `c7`,\r\n     D101.c6 as `c8`,\r\n     D101.c7 as `c9`,\r\n     D101.c8 as `c10`,\r\n     D101.c9 as `c11`,\r\n     D101.c10 as `c12`,\r\n     D101.c11 as `c13`,\r\n     D101.c12 as `c14`,\r\n     D101.c13 as `c15`,\r\n     D101.c14 as `c16`,\r\n     D101.c15 as `c17`\r\nfrom \r\n     (select T1000001.bikeid as `c1`,\r\n               T1000001.birthyear as `c2`,\r\n               T1000001.endstationid as `c3`,\r\n               T1000001.endstationlatitude as `c4`,\r\n               T1000001.endstationlongitude as `c5`,\r\n               T1000001.endstationname as `c6`,\r\n               T1000001.gender as `c7`,\r\n               T1000001.startstationid as `c8`,\r\n               T1000001.startstationlatitude as `c9`,\r\n               T1000001.startstationlongitude as `c10`,\r\n               T1000001.startstationname as `c11`,\r\n               T1000001.starttime as `c12`,\r\n               T1000001.stoptime as `c13`,\r\n               T1000001.tripduration as `c14`,\r\n               T1000001.usertype as `c15`\r\n          from \r\n               (select * from bike_trips bike_trips limit 50000) T1000001\r\n     ) D101 limit 21\n17/09/11 21:06:15 INFO SparkExecuteStatementOperation: Running query 'use default' with 4959fef1-7dc9-4584-9f6c-5955f804d39f\n17/09/11 21:11:18 INFO SparkExecuteStatementOperation: Running query 'use default' with 407b6549-4bdb-4557-b0ae-749d3bb0c217\n17/09/11 21:11:33 INFO SparkExecuteStatementOperation: Running query 'use default' with b1b13c5a-2662-497a-ac11-eb4fda9e7c1a\n17/09/11 21:11:33 INFO SparkExecuteStatementOperation: Running query 'select * from (select * from bike_trips bike_trips limit 50000) T0 WHERE 1=0' with ac361b6e-ed38-477b-b01b-c0f655482ca7\n17/09/11 21:11:33 INFO SparkSqlParser: Parsing command: select * from (select * from bike_trips bike_trips limit 50000) T0 WHERE 1=0\n17/09/11 21:11:34 INFO SparkExecuteStatementOperation: Running query 'use default' with 67d4d2ea-1407-4b1e-91ed-2c27aa8d5b43\n17/09/11 21:11:35 INFO SparkExecuteStatementOperation: Running query 'select 0 as `c1`,\r\n     ROW_NUMBER() OVER ( ORDER BY D101.c1) as `c2`,\r\n     D101.c1 as `c3`,\r\n     D101.c2 as `c4`,\r\n     D101.c3 as `c5`,\r\n     D101.c4 as `c6`,\r\n     D101.c5 as `c7`,\r\n     D101.c6 as `c8`,\r\n     D101.c7 as `c9`,\r\n     D101.c8 as `c10`,\r\n     D101.c9 as `c11`,\r\n     D101.c10 as `c12`,\r\n     D101.c11 as `c13`,\r\n     D101.c12 as `c14`,\r\n     D101.c13 as `c15`,\r\n     D101.c14 as `c16`,\r\n     D101.c15 as `c17`\r\nfrom \r\n     (select T1000001.bikeid as `c1`,\r\n               T1000001.birthyear as `c2`,\r\n               T1000001.endstationid as `c3`,\r\n               T1000001.endstationlatitude as `c4`,\r\n               T1000001.endstationlongitude as `c5`,\r\n               T1000001.endstationname as `c6`,\r\n               T1000001.gender as `c7`,\r\n               T1000001.startstationid as `c8`,\r\n               T1000001.startstationlatitude as `c9`,\r\n               T1000001.startstationlongitude as `c10`,\r\n               T1000001.startstationname as `c11`,\r\n               T1000001.starttime as `c12`,\r\n               T1000001.stoptime as `c13`,\r\n               T1000001.tripduration as `c14`,\r\n               T1000001.usertype as `c15`\r\n          from \r\n               (select * from bike_trips bike_trips limit 50000) T1000001\r\n     ) D101 limit 21' with 5a21786d-d5d0-4e1d-9c24-0fbc80fd4ec1\n17/09/11 21:11:35 INFO SparkSqlParser: Parsing command: select 0 as `c1`,\r\n     ROW_NUMBER() OVER ( ORDER BY D101.c1) as `c2`,\r\n     D101.c1 as `c3`,\r\n     D101.c2 as `c4`,\r\n     D101.c3 as `c5`,\r\n     D101.c4 as `c6`,\r\n     D101.c5 as `c7`,\r\n     D101.c6 as `c8`,\r\n     D101.c7 as `c9`,\r\n     D101.c8 as `c10`,\r\n     D101.c9 as `c11`,\r\n     D101.c10 as `c12`,\r\n     D101.c11 as `c13`,\r\n     D101.c12 as `c14`,\r\n     D101.c13 as `c15`,\r\n     D101.c14 as `c16`,\r\n     D101.c15 as `c17`\r\nfrom \r\n     (select T1000001.bikeid as `c1`,\r\n               T1000001.birthyear as `c2`,\r\n               T1000001.endstationid as `c3`,\r\n               T1000001.endstationlatitude as `c4`,\r\n               T1000001.endstationlongitude as `c5`,\r\n               T1000001.endstationname as `c6`,\r\n               T1000001.gender as `c7`,\r\n               T1000001.startstationid as `c8`,\r\n               T1000001.startstationlatitude as `c9`,\r\n               T1000001.startstationlongitude as `c10`,\r\n               T1000001.startstationname as `c11`,\r\n               T1000001.starttime as `c12`,\r\n               T1000001.stoptime as `c13`,\r\n               T1000001.tripduration as `c14`,\r\n               T1000001.usertype as `c15`\r\n          from \r\n               (select * from bike_trips bike_trips limit 50000) T1000001\r\n     ) D101 limit 21\n17/09/11 21:12:01 INFO SparkExecuteStatementOperation: Running query 'use default' with 94b8c69f-0669-4bec-a452-44aa4d00340a\n17/09/11 21:12:01 INFO SparkExecuteStatementOperation: Running query 'select * from (select * from bike_trips bike_trips limit 50000) T0 WHERE 1=0' with 26e39455-fc8a-4403-9f58-edc3984c820a\n17/09/11 21:12:01 INFO SparkSqlParser: Parsing command: select * from (select * from bike_trips bike_trips limit 50000) T0 WHERE 1=0\n17/09/11 21:12:02 INFO SparkExecuteStatementOperation: Running query 'use default' with 2a9ef43c-565c-4f22-ab21-e3d961ef40f7\n17/09/11 21:12:02 INFO SparkExecuteStatementOperation: Running query 'select T0.tripduration as `tripduration`, T0.starttime as `starttime`, T0.stoptime as `stoptime`, T0.startstationid as `startstationid`, T0.startstationname as `startstationname`, T0.startstationlatitude as `startstationlatitude`, T0.startstationlongitude as `startstationlongitude`, T0.endstationid as `endstationid`, T0.endstationname as `endstationname`, T0.endstationlatitude as `endstationlatitude`, T0.endstationlongitude as `endstationlongitude`, T0.bikeid as `bikeid`, T0.usertype as `usertype`, T0.birthyear as `birthyear`, T0.gender as `gender` from (select * from bike_trips bike_trips limit 50000) T0' with a44e18ef-999f-4c85-9cdb-f5be0525c557\n17/09/11 21:12:02 INFO SparkSqlParser: Parsing command: select T0.tripduration as `tripduration`, T0.starttime as `starttime`, T0.stoptime as `stoptime`, T0.startstationid as `startstationid`, T0.startstationname as `startstationname`, T0.startstationlatitude as `startstationlatitude`, T0.startstationlongitude as `startstationlongitude`, T0.endstationid as `endstationid`, T0.endstationname as `endstationname`, T0.endstationlatitude as `endstationlatitude`, T0.endstationlongitude as `endstationlongitude`, T0.bikeid as `bikeid`, T0.usertype as `usertype`, T0.birthyear as `birthyear`, T0.gender as `gender` from (select * from bike_trips bike_trips limit 50000) T0\n"}]}},{"dateUpdated":"2017-09-05T21:23:21+0000","config":{"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"results":{},"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1504646601871_1886918038","id":"20170504-171816_753503470","dateCreated":"2017-09-05T21:23:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1320"}],"name":"xtra Connecting DV Desktop and Spark","id":"2CSBTXV7T","angularObjects":{"2CUR9TKC3:shared_process":[],"2CV6GZ6KY:shared_process":[],"2CRXRKTZS:shared_process":[],"2CUEWBE5C:shared_process":[],"2CUNV7BVE:shared_process":[],"2CRQ5UM9P:shared_process":[],"2CRHKT1V7:shared_process":[],"2C4U48MY3_spark2:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}